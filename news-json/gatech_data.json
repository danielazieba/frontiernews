{"articles": [{"source": "Georgia Institute of Technology", "title": "That's a Wrap! Video Highlights 2018 GT Computing Community Achievements", "link": "/news/615133/thats-wrap-video-highlights-2018-gt-computing-community-achievements", "date": "12/07/2018", "content": "It\u2019s been another successful year for the GT Computing community! To celebrate the success of our community, we\u2019ve pulled together some College of Computing news highlights from the past 12 months.\nOf course, from innovation and entrepreneurship to accolades and achievements, it\u2019s impossible to capture everything in a two-minute video (Yes, just two minutes!).\nSo the stories featured in the GT Computing: 2018 Year in Review are meant to represent all of the accomplishments our students and faculty have achieved this year.\nHere\u2019s to a happy and healthy holiday season and another successful year in 2019!\n"}, {"source": "Georgia Institute of Technology", "title": "HiCOO Takes Home Best Student Paper Title of Supercomputing 2018 by Creating a New Storage Format", "link": "/news/615074/hicoo-takes-home-best-student-paper-title-supercomputing-2018-creating-new-storage", "date": "12/06/2018", "content": "Jiajia Li\u00a0is a recently graduated Ph.D. student from the\u00a0School of Computational Science and Engineering\u00a0(CSE) with a knack for optimizing tensor algorithms and creating memorable pun-filled paper titles. Li\u2019s latest work,\u00a0Hierarchical Storage of Sparse Tensors, nicknamed HiCOO, focuses on both of these attributes.\nHiCOO was awarded the prestigious title of best student paper at this year\u2019s International Conference for\u00a0High Performance Computing, Networking, Storage, and Analysis, commonly referred to as Supercomputing (SC).\nWinning the best student paper award at this well-established and increasingly competitive conference program, which boasted an impressive\u00a0288 technical paper submissions with 68 ultimately being accepted\u00a0this year, is no small feat.\nHowever, for Li, who holds a second Ph.D. degree in computer architecture, the journey to effectively alter a process is half the battle and half the fun in research.\n\u201cFor me, it isn\u2019t about the outcome, but rather what I can explore in the process along the way,\u201d she said. \u201cTensors algorithms are a way to break down data by organizing or viewing it in a certain manner to find what connects the different factors. Sparse tensors are just a specific kind of tensor.\u201d\nFor sparse tensor computations, there is tension among storage, speed, and flexibility. With traditional methods, you can usually get just two of these three traits. For example, a computation can be fast and flexible at the price of more storage. Or, it can be compact and flexible, but also slow.\n\u201cWe wanted to create a storage format for tensors that was all three: compact, fast, and flexible,\u201d said Li.\nAuthors of HiCOO, which includes Li and CSE Associate Professors\u00a0Rich Vuduc\u00a0and\u00a0Jimeng Sun, were inspired by the work of Lawrence Berkeley National Lab Staff Scientist\u00a0Aydin Bulu\u00e7\u00a0which focuses on sparse matrices, the lower dimensional analogue of a tensor.\u00a0\n\u201cWe saw an opportunity to extend those ideas to sparse tensors,\u201d explained Li. \u201cWe believe HiCOO is smaller, faster, and simpler to update [when the data is changing] than state-of-the-art alternatives. So, we think it will be easier to use in tensor libraries, tools, and data mining applications, which today include e-commerce, healthcare, security, and deep learning, to name a few.\u201d\nVuduc said, \u201cAn example of this use comes from Jimeng Sun\u2019s work where his team is\u00a0trying to find structure in electronic health records\u00a0(EHRs). There is always a way to organize the data along certain dimensions, for example, a patient could be considered one dimension, the diagnosis they receive would be a second, and their treatment a third.\u201d\nAs one could imagine, the way in which these dimensions could be combined could yield endless outcomes. Which is why the ability to store data of this size in a way that respects order, quickly computes, and uses as minimal amount of storage as possible is a critically needed function.\u00a0\u00a0\n\u201cBasically, the formats that existed already could give you two of those areas: All the competition could either have a small data structure which took less storage or if you wanted to access the data in a different order it could but would be slower,\u201d said Li. \u201cHiCOO breaks the mold of its predecessors by proposing a new storage format for sparse tensors [called Hierarchical COOrdinate], that accomplishes all three.\u201d\nLi currently works as a computer scientist at the\u00a0High Performance Computing Group\u00a0of\u00a0Pacific Northwest National Laboratory\u00a0(PNNL) in Richland, Washington.\u00a0\nRead the PNNL press release of HiCOO\u00a0here.\n"}, {"source": "Georgia Institute of Technology", "title": "Computing Professors Recognized With Prestigious ACM Fellowships", "link": "/news/615032/computing-professors-recognized-prestigious-acm-fellowships", "date": "12/05/2018", "content": "Two Georgia Tech College of Computing faculty members have been named as Fellows of the Association for Computing Machinery (ACM).\nIn an announcement made today, Executive Associate Dean Charles Isbell and School of Interactive Computing Professor Amy Bruckman were named as two of 56 ACM Fellows selected for 2018.\nAccording to the ACM news release, \u201cthe accomplishments of the 2018 ACM Fellows underpin the technologies that define the digital age and greatly impact our professional and personal lives. ACM Fellows are composed of an elite group that represents less than 1 percent of the Association\u2019s global membership.\u201d\nIsbell, a Georgia Tech alumnus, was named as an ACM Fellow \u201cfor contributions to interactive machine learning; and for contributions to increasing access and diversity in computing.\u201d\nThe organization selected Bruckman for her \u201ccontributions to collaborative computing and foundational work in Internet research ethics.\u201d\n\u201cIn society, when we identify our tech leaders, we often think of men and women in industry who have made technologies pervasive while building major corporations,\u201d said ACM President Cherri M. Pancake. \u201cAt the same time, the dedication, collaborative spirit and creativity of the computing professionals who initially conceived and developed these technologies goes unsung. The ACM Fellows program publicly recognizes the people who made key contributions to the technologies we enjoy. Even when their work did not directly result in a specific technology, they have made major theoretical contributions that have advanced the science of computing. We are honored to add a new class of Fellows to ACM\u2019s ranks and we look forward to the guidance and counsel they will provide to our organization.\u201d\nUnderscoring ACM\u2019s global reach, the 2018 Fellows hail from universities, companies and research centers in Finland, Greece, Israel, Sweden, Switzerland, and the US.\nThe 2018 Fellows have been cited for numerous contributions in areas including accessibility, augmented reality, algorithmic game theory, data mining, storage, software and the World Wide Web.\nACM will formally recognize its 2018 Fellows at the annual Awards Banquet, to be held in San Francisco on June 15, 2019. Additional information about the 2018 ACM Fellows, as well as previous ACM Fellows, is available through the ACM Fellows site.\n"}, {"source": "Georgia Institute of Technology", "title": "Eric Vigoda Named American Mathematical Society Fellow", "link": "/news/614883/eric-vigoda-named-american-mathematical-society-fellow", "date": "12/03/2018", "content": "The American Mathematical Society (AMS) named School of Computer Science (SCS) Professor Eric Vigoda a new fellow for 2019.\nThe 30,000-plus members of AMS nominate individuals who \u201chave made outstanding contributions to the creation, exposition, advancement, communication, and utilization of mathematics.\u201d They selected Vigoda for his contributions to theoretical computer science, emphasizing his work on interactions with probability, combinatorics, and statistical physics.\n\u201cI'm honored to receive this recognition of my peers,\u201d Vigoda said.\nVigoda joined Georgia Tech in 2004, where he has become a premier researcher on the connections between statistical physics phase transitions and Markov Chain Monte Carlo algorithms. He is also the director of the Algorithms and Randomness Center in SCS.\n\u201cThis honor recognizes Eric Vigoda\u2019s high standing in the academic community for his work in algorithms, notably on mixing and other random processes,\u201d SCS Chair Lance Fortnow said.\nVigoda joins SCS faculty Professors Dana Randall and Prasad Tetali as AMS Fellows.\n\u00a0\n"}, {"source": "Georgia Institute of Technology", "title": "Database Systems Expert Joy Arulraj Joins School of Computer Science", "link": "/news/614892/database-systems-expert-joy-arulraj-joins-school-computer-science", "date": "12/03/2018", "content": "Database systems is one of the most wide-reaching fields in computer science, influencing everything from healthcare to government. For new Assistant Professor Joy Arulraj, database systems allow him to make an impact in as many research areas as possible.\n\u201cI\u2019ve always been into solving puzzles, and with databases, you\u2019re free to explore different parts of the data processing pipeline and apply different skill sets,\u201d he said.\nWith Arulraj\u2019s arrival in fall 2018 as the Barry Dickman Early Career Professor, he strengthened an already robust data science team in the School of Computer Science. Professor Shamkant Navathe designs and models databases. Assistant Professor Xu Chu focuses on data cleaning. Arulraj complements the others with his emphasis on data processing on modern hardware.\nBuilding non-volatile memory database systems\n\u201cHardware keeps changing all the time, so it\u2019s important to revisit the design decisions you make in software systems,\u201d he said.\nArulraj explored this in his doctoral work at Carnegie Mellon University on non-volatile memory database systems. In the past, databases have relied on two types of storage technologies: fast but volatile memory and slow but durable storage. Recently, however, device manufactures created a new class of memory technologies that are both fast and persistent, blurring the gap between memory and storage. These technologies invalidate many design assumptions that computer scientists have had for decades. Arulraj plans to fill the gap by redesigning database systems to work with these new protocols.\n\u201cYou were constrained by the characteristics of traditional memory and storage technologies for a long, long time, but finally you have something new,\u201d Arulraj said. \u201cFive years ago, working with these new technologies was like a moonshot, but now it\u2019s a burgeoning field in computer science.\u201d\nNext-generation multimedia database systems \nSince he arrived at Tech, Arulraj is refocusing his research on video analytics. Multimedia databases are challenging because data is unstructured. With the right tools, though, a user could automatically analyze their photostream to determine the last time they saw a friend or went hiking.\nRecent advances in machine learning and graphics processing units have increased the accuracy and speed of video analytics. These developments enable researchers to build systems that can query media, like the one Arulraj is currently working on.\nArulraj\u2019s first course at Tech reflects this research. The seminar combines data analytics and deep learning, though he will regularly teach database system implementation in the spring. The core course teaches how to build data processing systems, covering the whole pipeline of processing data.\n\u201cThis course will be a much more modern take on database systems research,\u201d he said.\nModern databases cross disciplines, and this was one of the reasons Arulraj chose Georgia Tech.\n\u201cThere are more opportunities here to collaborate across the board, and that\u2019s the future of database systems.\u201d\n"}, {"source": "Georgia Institute of Technology", "title": "New IC Assistant Professor Matthew Gombolay Takes Flight at Georgia Tech", "link": "/news/614861/new-ic-assistant-professor-matthew-gombolay-takes-flight-georgia-tech", "date": "11/30/2018", "content": "School of Interactive Computing Assistant Professor Matthew Gombolay was always interested in space and aviation. He had taken some flying lessons as a teen and after college decided that he wanted to finish his pilot certification. He had received some prodding from his then-girlfriend \u2013 now wife \u2013 in the form of a flight lesson in the Washington D.C. area.\nAlthough he had done classes when he was around 15 or 16 years old, he treated it like it was a brand-new experience for him.\n\u201cIt kind of was,\u201d said Gombolay, who had backed out of his lessons when he was younger after being told he was ready to fly solo about eight hours in. \u201cI got a little shy and embarrassed and quiet, but I always wanted to do it.\u201d\nAnd he did, receiving his certification after finishing his undergraduate degree. It was everything he had hoped. It was a different experience than his studies and his research, which is mostly an exercise of his mental capabilities. Flying required mental effort, but also physical \u2013 his hands, his feet, coordination of his body. It was something that he appreciated.\nBut it was also something that helped guide him on the path he wanted to follow for his research.\nEarning his wings\nHis studies lie in a number of areas, namely robotics, artificial intelligence (AI), machine learning (ML), human factors engineering, human-robot interaction, planning and scheduling, queuing theory, real-time systems, and operations research.\nA lot of that was borne out of a specific experience he had during a flight lesson.\n\u201cI was flying the aircraft, and my instructor told me to plot a diversion to another airport because we were going to pretend that the airport I was headed to had some weather that would prevent me from landing,\u201d he explained. \u201cThat\u2019s a lot of work. You have to fly the plane, you have to get out a map and do all the segments you\u2019ll take, measure the angles, measure distances, calculate fuel burn and figure out how you\u2019ll change your flight plan.\u201d\nSo, when given the directive to use autopilot while doing the calculations, Gombolay input his altitude and heading and stuck his head into his calculations.\nIt was a mistake.\n\u201cShe told me I broke the first rule,\u201d he said. \u201cYou have to aviate, navigate, then communicate. I was so desperate to handle the workload that I turned over the first duty to an autopilot and didn\u2019t really know how it worked.\n\u201cIf there was Mt. Everest in front of us, it wasn\u2019t going to steer away. If there was another plane, it wasn\u2019t going to steer away. If it was low on fuel, it wasn\u2019t going to tell me to turn back.\u201d\nIt was a realization of how quickly and easily humans are willing to trust automated systems that may not be entirely prepared to handle that workload. Your willingness to be vulnerable is a huge choice, he said.\n\u201cI can trust something, but that doesn\u2019t make it trustworthy,\u201d he said.\nThis realization helped guide him to human factors engineering during his graduate studies at the Massachusetts Institute of Technology, where he earned his Ph.D. in Autonomous Systems in 2017.\nMaking robots personal\nSince joining Georgia Tech in the beginning of the fall semester, Gombolay has been growing his lab and beginning a handful of new projects that build on some of his past research.\nOne recently-funded project done in collaboration with MIT focuses on how humans make decisions as part of a team \u2013 the strategies, the styles, etc. Using a video game as an example, he explained that some individuals may prefer an aggressive approach versus a defensive.\n\u201cThese different stylistic things emerge naturally in how humans solve problems,\u201d Gombolay said. \u201cBut that diversity isn\u2019t very pleasant for machine learning algorithms because the average of two different people is not a third good person. It\u2019s just an ugly mess.\u201d\nHis lab is looking at ways to synthesize policies that can leverage all of the data about styles and strategies and tailor to individual differences. Health care is an example, Gombolay said. Consider a physical therapist who wants to teach a robot how to take care of a patient at home. Each therapist has his or her own unique style of stretching, massaging, and strength-training their patients, and each patient has a unique malady, response profile, or anatomy.\n\u201cMost algorithms today that would be put on a robot to help it learn how to care for a patient would either apply a one-size-fits-all model, which can result in a blend that helps nobody, or train from scratch for each new patient-therapist combination, which would take way too long to be a practical solution.\n\u201cWe want to leverage every robot\u2019s collective experience while still being able to tailor the behavior to each individual.\u201d\nOther areas of focus for his lab include manufacturing, health care, and new areas in reinforcement learning. He is currently funding three students, and his lab includes one research scientist.\nA few hobbies\nWhen he\u2019s not doing research \u2013 or maybe flying a plane \u2013 Gombolay is usually taking part in one of his other hobbies, like tennis or building models of Star Wars or Star Trek ships with his LEGOs and MegaBloks.\nHe\u2019s also a musician, who started on the violin and piano before adding an alto saxophone to the mix and later a guitar. The guitar is his instrument of choice nowadays, and he\u2019s spent a lot of time using it in bands in college \u2013 church, a cover band, talent shows and the like.\nHe\u2019s found a couple of people on campus, like fellow IC Professor Seth Hutchinson, who don\u2019t mind getting together for a jam session now and again.\nAs the Star Wars and Star Trek models might suggest, Gombolay has always been fascinated by space and space travel. It\u2019s influenced his path in research and, who knows, in another life he might have been an astronaut.\n\u201cMaybe,\u201d he said when asked whether that was ever an ambition. \u201cWho knows? Maybe one day I\u2019ll be on a rocket to Mars. I\u2019ll take my wife and the kid with me. She\u2019s a physician, so she\u2019ll take care of us.\u201d\n"}, {"source": "Georgia Institute of Technology", "title": "Georgia Tech Researchers Helping Develop Game to Improve STEM Learning in Chronically-Ill Children", "link": "/news/614766/georgia-tech-researchers-helping-develop-game-improve-stem-learning-chronically-ill", "date": "11/29/2018", "content": "Georgia Tech researchers are partnering with a Georgia-based game developer on a $1.5 million National Institutes of Health (NIH) Small Business Innovation Research grant to help chronically-ill children maintain their educational development.\nWith an emphasis on science, technology, engineering, and math (STEM) subjects, researchers from the Schools of Interactive Computing and Biomedical Engineering are teaming with Thrust Interactive, Inc., to create digital games that can help these kids that tend to miss a lot of school due to their illnesses.\nAssociate Professor Betsy DiSalvo (IC) and Associate Professor Wilbur Lam (BME) are leading the project, which will span two years under the current terms of the grant. Their goal is to take advantage of the time chronically-ill children spend in waiting rooms, having transfusions, or other times spent outside of the classroom.\nThe digital games are based on physical tabletop games created by members of Lam\u2019s lab. Led by Dr. Elaissa Hardy\u00a0(Emory), a team of BME undergraduate students originally created the tabletop games to help kids in the hospital with sickle cell disease engage with STEM subjects.\nLam\u2019s lab has worked with DiSalvo and Thrust for the past two years to pilot test digital versions of these games. The new NIH grant will be used to develop findings from the pilot testing so the research team can better understand how to create a scalable model that can be used in hospitals across the country.\nAnother challenge the team wants to address is the difficulty children face in discussing their diseases with others. Common illnesses such as diabetes and asthma, as well as those less common like sickle cell and cystic fibrosis, can be challenging topics for children, particularly in their early teen years.\n\u201cThe middle schoolers we interviewed told us it was awkward to talk about their disease,\u201d DiSalvo said. \u201cSometimes, they got bullied or had issues finding ways to discuss it with their peers. Previous research has shown that if you can have kids play a game around their disease, they\u2019ll engage about it more in conversation with peers and families.\n\u201cIt can diminish the stigma, and it also positions them as experts. When children feel like they have expertise, they are usually willing to dive deeper and learn more to maintain their expert position.\u201d\nA better understanding of their disease at this age is critical for young people beginning to take charge of managing their own care, according to the researchers.\n\u201cThese adolescents are beginning to transition into adulthood, so managing their illness is beginning to become their responsibility,\u201d DiSalvo said. \u201cThose transitions are difficult because, in doctor visits, parents tend to dominate the conversation while kids sit in the background, not really asking questions or engaging. It\u2019s important to change that dynamic at this age.\u201d\nThe researchers are investigating three different approaches to the digital games to determine the best learning experience outcomes. They will test content using:\n\nPictures and words\nPictures and audio\nPictures, words, and audio.\n\nFollow-up comprehension tests after will help determine which approach leads to the best results. Those tests will take up the first year of the project, with the second year focused on testing the application in live hospital settings.\n\u201cWe want it to be so fun and engaging that they don\u2019t think of it as an educational game,\u201d said Sarah Boyd, a Thrust Interactive team member who will work on design.\n\u201cIt\u2019s fun, and they\u2019re learning. There are existing approaches relating to education of disease, but they aren\u2019t as engaging. We want a fun and engaging game first, but then they\u2019re going to be learning about their health as they engage.\u201d\nThrust Interactive has elicited help from Paul Jenkins, a comic book writer and video game creator who has been involved with Teenage Mutant Ninja Turtles, a number of Marvel Comics titles, and video games like God of War and The Darkness.\n"}, {"source": "Georgia Institute of Technology", "title": "Tech Ranks Among Top Universities Globally in Computer Science, Engineering", "link": "/news/614794/tech-ranks-among-top-universities-globally-computer-science-engineering", "date": "11/29/2018", "content": "Georgia Tech has made the Top 10 in global rankings in the key subject areas of computer science and engineering.\nIn the latest Times Higher Education subject rankings for computer science, the Institute is ranked seventh internationally. Tech was the top American public university on the list. Ranked just behind Stanford University, MIT, and the United Kingdom\u2019s University of Oxford and University of Cambridge, its computer science program landed ahead of both Harvard and Princeton.\nIn the engineering rankings, Georgia Tech appeared in the Top 10, and was also the top-rated public American university.\nThe London-based Times Higher Education has been providing ranked data on international universities since 2004. Their 2018-19 research includes more than 1,250 higher education institutions from 86 nations.\u00a0\n\u00a0\nGeorgia Tech\u2019s full rankings:\nComputer Science: 7\nEngineering: 10\nPhysical Science: 44\nBusiness and Economics: 51\nSocial Sciences: 72\nPsychology: 100\nTo see the full rankings in detail, visit:\n\u2022 Engineering & Technology https://www.timeshighereducation.com/world-university-rankings/2019/subject-ranking/engineering-and-IT\n\u2022 Computer Science https://www.timeshighereducation.com/world-university-rankings/2019/subject-ranking/computer-science\n"}, {"source": "Georgia Institute of Technology", "title": "David Devecsery Wants to Build Better Systems ", "link": "/news/614683/david-devecsery-wants-build-better-systems", "date": "11/27/2018", "content": "In the world of academia, sometimes the most innovative research isn\u2019t practical.\u00a0Yet new Assistant Professor\u00a0David Devecsery\u00a0believes\u00a0he has a duty to build usable systems.\u00a0\n\u201cI want to create better systems and ways of doing things with hopes someone else will use it,\u201d he said.\nDeveloping\u00a0systems\nDevecsery\u00a0has been working on finding solutions to real-world problems since college. In his junior year as a computer science student\u00a0at\u00a0the University of Michigan, where he also completed his M.S. and Ph.D.,\u00a0Devecsery\u00a0joined an embedded systems project to help spread information in the developing world.\u00a0\nThe Talking Book was\u00a0an audio computer\u00a0created\u00a0to transmit information in some of the world\u2019s poorest countries,\u00a0where electricity is unreliable and cellphones are too expensive.\nYet the device\u2019s original format cost $45 to build and wasn\u2019t energy efficient, so\u00a0Devecsery\u00a0and his team\u00a0developed an\u00a0inexpensive\u00a0custom microprocessor.\u00a0He\u00a0helped design\u00a0the project from the original chip to the computer\u2019s applications. The three-year\u00a0endeavor\u00a0solidified his interest in systems.\u00a0\u00a0\nDesigning and building an entire computing stack from the ground up\u00a0came with challenges. Debugging the chip was no easy feat, especially when the debugging interface itself had a bug.\n\u201cIt\u2019s very nice to look at buggy software and make it reliable and understand how it doesn\u2019t work,\u201d he said.\u00a0\nSolving system failure\nAs software systems grow more complex, they become\u00a0more challenging\u00a0to debug. Having tools to analyze and understand the space is important if software is going to be scaled effectively. With this in mind,\u00a0Devecsery\u2019s\u00a0systems research has focused on two\u00a0avenues:\u00a0eidetic systems and optimistic hybrid analysis.\nEidetic computer systems have the ability to recall any past setup or state of the computer. Therefore,\u00a0they\u00a0can be useful in recreating events to help figure out what happened during a system failure or a cyberattack. The process is typically time-consuming and manual, but Devecsery\u2019s\u00a0research automates it. With this information, researchers can learn how to improve software or debug more efficiently.\u00a0\n\u201cMost\u00a0of these scenarios are preventable\u00a0with techniques we know today,\u00a0but most are too expensive to do practically,\u201d\u00a0Devecsery\u00a0said. \u201cThe research is how\u00a0we can\u00a0take techniques and make them more efficient so we can use them today.\u201d\nGeorgia Tech researchers are already using\u00a0Devecsery\u2019s\u00a0work.\u00a0One of the most promising cybersecurity breakthroughs of the last year was the\u00a0Refinable Attack INvestigation (RAIN), which is a new software system that enables researchers to accurately and quickly determine how and when intruders entered a network, what data they took, and what systems were compromised.\u00a0\u00a0\nOptimistic hybrid analysis helps to prevent\u00a0many software bugs, such as\u00a0data-races.\u00a0 A data-race occurs\u00a0when a system attempts to perform two or more operations\u00a0on the same data simultaneously. Although computer scientists already have the tools to do\u00a0data-race\u00a0detection, they slow the system down by 10 times and are often inaccurate.\u00a0\nDevecsery\u2019s\u00a0work uses a strategic mix of static (examining code without running the program) and dynamic (examining code while running the program), or hybrid, analysis.\u00a0By making dynamic observations of the code, researchers can trim down how much static analysis they must do, making\u00a0it\u00a0much more efficient.\u00a0\nTraining\u00a0better\u00a0systems\u00a0researchers\nDevecsery\u00a0is also passionate about training future researchers to do this work.\u00a0He has been teaching since he joined his high school\u2019s tutoring club and considers it\u00a0one of the main reasons he was drawn to academia.\u00a0He prefers an active learning approach where he gives students difficult questions to discuss with a partner and then apply to a real-world situation.\nAfter joining the School of Computer Science in the fall semester, he found the next generation of researchers. The students are \u201cextremely intelligent and think creatively about research,\u201d according to\u00a0Devecsery.\u00a0\n\u00a0\u201cI really believe when you give students a challenge and they come to you for help, you never really tell them the answer,\u201d he said. \u201cYou just turn on a light down that path and encourage them to take a step in the right direction.\u201d\n"}, {"source": "Georgia Institute of Technology", "title": "Katabi Distinguished Lecture Shows How Machine Learning Can Revolutionize Healthcare", "link": "/news/614514/katabi-distinguished-lecture-shows-how-machine-learning-can-revolutionize-healthcare", "date": "11/21/2018", "content": "\u00a0\nMachine learning (ML) techniques could improve healthcare monitoring for the chronically ill. Now metrics can be measured without contacting the patient whatsoever. Dina Katabi, a Massachusetts Institute of Technology professor, gave the School of Computer Science\u2019s distinguished lecture on this topic, Deep Learning Models for Tracking People through Walls and Sensing their Vital Signs, on Nov. 8.\n\u201cRadio frequencies allow you to see through walls,\u201d Katabi said. \u201cThis can offer valuable data on what people are doing and how they are doing it.\u201d\nAlthough it\u2019s easy enough to measure reflection time off the human body to determine if a person is moving, currently it\u2019s harder to measure actual actions or poses. Reflections are a fallible measurement tool because most body parts don\u2019t register and secondary reflections can muddle data. However, human motion across time can be measured. This is where deep learning comes in.\nA neural network can fill in the missing information and create a body part that didn\u2019t register during the first radio frequency reading. Once the neural network is trained on some data, a camera isn\u2019t even necessary.\n\u201cThe network can see through walls even if we can\u2019t,\u201d Katabi said.\nThis is more than just a theory. Katabi and her research team have put it into practice. They trained the neural network on 50 hours of data over 50 locations, capturing daily activities. Then they applied the data to healthcare issues.\nKatabi found that the neural network can determine a person\u2019s breathing with 97 percent accuracy compared to the FDA-approved chest band. Sleep disorders can be analyzed with 80 percent accuracy. This is ground-breaking because these metrics are typically measured with invasive chest bands or wires that are uncomfortable to the patient.\nUltimately this could revolutionize healthcare spending. Chronic conditions drive up healthcare costs because people usually seek treatment when they are most extreme. Using radio frequencies to monitor conditions like Parkinson\u2019s or congestive heart disease could enable doctors to intervene before hospitalization is required. They have already deployed the technology to 200 homes.\n\u201cAll tools for monitoring health are cumbersome and invasive,\u201d Katabi said. \u201cNo one will live like this continuously. A wireless device analyzes wireless signals and uses ML algorithms to measure breath, sleep, heart rate, or gait speed without asking a patient to wear any device or change his or her behavior. It\u2019s completely passive.\u201d\n"}]}