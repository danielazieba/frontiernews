{"articles": [{"source": "MIT", "title": "With these nanoparticles, a simple urine test could diagnose bacterial pneumonia ", "link": "/2018/nanoparticles-urine-diagnose-bacterial-pneumonia-1129", "date": "8", "content": "Pneumonia, a respiratory disease that kills about 50,000 people in the United States every year, can be caused by many different microbes, including bacteria and viruses. Rapid detection of pneumonia is critical for effective treatment, especially in hospital-acquired cases which are often more severe. However, current diagnostic approaches often take several days to return definitive results, making it harder for doctors to prescribe the right treatment.\nMIT researchers have now developed a nanoparticle-based technology that could be used to improve the speed of diagnosis. This type of sensor could also be used to monitor whether antibiotic therapy has successfully treated the infection, says Sangeeta Bhatia, the John and Dorothy Wilson Professor of Health Sciences and Technology and Electrical Engineering and Computer Science and the senior author of the study.\n\u201cIf the patient\u2019s symptoms go away, then you assume the drug is working. But if the patient\u2019s symptoms don\u2019t go away, then you would want to see if the bacteria is still growing. We were trying to address that issue,\u201d says Bhatia, who is also a member of MIT\u2019s Koch Institute for Integrative Cancer Research and Institute for Medical Engineering and Science.\nGraduate student Colin Buss and recent PhD recipient Jaideep Dudani are the lead authors of the paper, which appears online Nov. 29 in the journal EBioMedicine. Reid Akana, an MIT senior, and Heather Fleming, director of research for Bhatia\u2019s lab, are also authors of the paper.\nSensors in the body\nSeveral years ago, Bhatia and her colleagues developed a diagnostic approach that amplifies a signal from biomarkers already present in the body \u2014 specifically, enzymes called proteases, which chop up other proteins. The human genome encodes more than 500 different proteases, each of which targets different proteins.\nThe team developed nanoparticles coated with peptides (short proteins) that can be chopped up by certain proteases, such as those expressed by cancer cells. When these particles are injected into the body, they accumulate in tumors, if any are present, and proteases there chop the peptides from the nanoparticles. These peptides are eliminated as waste and can be detected by a simple urine test.\n\u201cWe\u2019ve been working on this idea that measuring enzyme activity could be a new way to peer inside the body,\u201d Bhatia says.\nIn recent studies, she has shown that this approach can be used to detect different types of cancers, including very small ovarian tumors, which could enable earlier diagnosis of ovarian cancer.\nFor their new study, the researchers wanted to explore the possibility of diagnosing infection by detecting proteases that are produced by microbes. They began with a species of bacteria called Pseudomonas aeruginosa, which can cause pneumonia and is a particularly common cause of hospital-acquired cases. Pseudomonas expresses a protease called LasA, so the researchers designed nanoparticles with peptides that can be cleaved by LasA.\nThe researchers also developed a second nanoparticle-based sensor that can monitor the host\u2019s immune response to infection. These nanoparticles are covered in peptides that are cleaved by a type of protease called elastase, which is produced by immune cells called neutrophils.\nIn some patients with pneumonia, even if an antibiotic clears out the bacteria causing the infection, a chest X-ray may still show inflammation because neutrophils are still active. Using these two sensors together could reveal whether an antibiotic has cleared the infection, in cases where a chest X-ray still shows inflammation after treatment.\n\u201cThe sensors can help you distinguish between whether there\u2019s an infection and inflammation, versus inflammation and no infection,\u201d Bhatia says. \u201cWhat we showed in the paper is that when you treat with the right antibiotic, the infection goes down but the inflammation persists.\u201d\nThe researchers also showed that if they treated mice with an ineffective antibiotic, both bacteria levels and inflammation levels stayed high. This kind of test could help to reveal whether an antibiotic is working, in cases where a patient\u2019s symptoms haven\u2019t improved within a few days.\nDiagnosing many infections\nFor this study, the researchers delivered the nanoparticles intravenously, but they are now working on a powdered version that could be inhaled.\nBhatia envisions that this approach could be used to determine whether a patient has bacterial or viral pneumonia, which would help doctors to decide if the patient should be given antibiotics or not. The definitive test, growing a bacterial culture from coughed up mucus, takes several days, so doctors base their decisions on the patients\u2019 symptoms and X-ray imaging \u2014 a process that may not always be accurate.\nTo create a more comprehensive diagnostic, Bhatia\u2019s lab is now working on adding peptides that could interact with proteases from other types of bacteria that cause pneumonia, as well as proteases that the host immune system produces in response to either viral or bacterial infection. The researchers are also working on sensors that could easily distinguish between active and dormant forms of tuberculosis.\nBhatia and others have started a company called Glympse Bio that has licensed the protease sensing technology and is now working on developing protease sensors for possible use in humans. Next year, they plan to begin a phase I clinical trial of a sensor that can detect liver fibrosis, an accumulation of scar tissue that can lead to cirrhosis.\u00a0\nThe research was funded by the Koch Institute Support (core) Grant from the National Cancer Institute, the Core Center Grant from the National Institute of Environmental Health Sciences, and the National Institute of Allergy and Infectious Diseases.\n"}, {"source": "MIT", "title": "Reproducing paintings that make an impression ", "link": "/2018/mit-csail-repaint-system-reproducing-paintings-make-impression-1129", "date": "8", "content": "The empty frames hanging inside the Isabella Stewart Gardner Museum serve as a tangible reminder of the world\u2019s biggest unsolved art heist. While\u00a0the original masterpieces may never be recovered, a team from MIT\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL) might be able to help, with a new system aimed at designing reproductions of paintings.\nRePaint uses a combination of 3-D printing and deep learning to authentically recreate\u00a0favorite paintings \u2014\u00a0regardless of different lighting conditions or placement. RePaint could be used to remake artwork for a\u00a0home, protect originals from wear and tear in museums, or even help companies create prints and postcards of historical pieces.\n\u201cIf you just reproduce the color of a painting as it looks in the gallery, it might look different in your home,\u201d says Changil Kim, one of the authors on a new paper about the system, which will be presented at ACM SIGGRAPH Asia in December. \u201cOur system works under any lighting condition, which shows a far greater color reproduction capability than almost any other previous work.\u201d\n\n\n\n\n\n\n\nTo test RePaint, the team reproduced a number of oil paintings created by an artist collaborator. The team found that RePaint was more than four times more accurate than state-of-the-art physical models at creating the exact color shades for different artworks.\nAt this time the reproductions are only about the size of a business card, due to the time-costly nature of printing. In the future the team expects that more advanced, commercial 3-D printers could help with making larger paintings more efficiently.\nWhile 2-D printers are most commonly used for reproducing paintings, they have a fixed set of just four inks (cyan, magenta, yellow, and black). The researchers, however, found a better way to capture a fuller spectrum of Degas and Dali. They used a special technique they\u00a0call\u00a0\u201ccolor-contoning,\u201d\u00a0which involves using a 3-D printer and 10 different transparent inks stacked in very thin layers, much like the wafers and chocolate in a Kit-Kat bar. They combined their method with a decades-old technique called half-toning, where an image is created by lots\u00a0of little colored\u00a0dots rather than continuous tones. Combining these, the team says, better captured the nuances of the colors.\nWith a larger color scope to work with, the question of what inks to use for which paintings still remained. Instead of using more laborious physical approaches, the team trained a deep-learning model to predict the optimal stack of different inks. Once the system had a handle on that, they fed in images of paintings and used the model to determine what colors should be used in what particular areas for specific paintings.\nDespite the progress so far, the team says they have a few improvements to make before they can whip up a dazzling duplicate\u00a0of \u201cStarry Night.\u201d For example, mechanical engineer Mike Foshey said they couldn\u2019t completely reproduce certain colors like cobalt blue due to a limited ink library. In the future they plan to expand this library, as well as create a painting-specific algorithm for selecting inks, he says. They also can hope to achieve better detail to account for aspects like surface texture and reflection, so that they can achieve specific effects such as glossy and matte finishes.\n\u201cThe value of fine art has rapidly increased in recent years, so there\u2019s an increased tendency for it to be locked up in warehouses away from the public eye,\u201d says Foshey. \u201cWe\u2019re building the technology to reverse this trend, and to create inexpensive and accurate reproductions that can be enjoyed by all.\u201d\nKim and Foshey worked on the system alongside lead author Liang Shi; MIT professor Wojciech Matusik;\u00a0former MIT postdoc Vahid Babaei, now Group Leader at Max Planck Institute of Informatics; Princeton University computer science professor Szymon Rusinkiewicz;\u00a0and former MIT postdoc Pitchaya Sitthi-Amorn, who is now a lecturer at Chulalongkorn University in Bangkok, Thailand.\nThis work is supported in part by the National Science Foundation.\n"}, {"source": "MIT", "title": "Student group explores the ethical dimensions of artificial intelligence", "link": "/2018/mit-student-group-explores-artificial-intelligence-ethics-1127", "date": "8", "content": "For years, the tech industry followed a move-fast-and-break-things approach, and few people seemed to mind as a wave of astonishing new tools for communicating and navigating the world appeared on the market.\nNow, amid rising concerns about the spread of fake news, the misuse of personal data, and the potential for machine-learning algorithms to discriminate at scale, people are taking stock of what the industry broke. Into this moment of reckoning come three MIT students,\u00a0Irene Chen,\u00a0Leilani Gilpin, and\u00a0Harini Suresh, who are the founders of the new\u00a0MIT AI Ethics Reading Group.\nAll three are graduate students in the Department of Electrical Engineering and Computer Science (EECS) who\u00a0had done stints in Silicon Valley, where they saw firsthand how technology developed with good intentions could go horribly wrong.\n\u201cAI is so cool,\u201d said\u00a0Chen during a chat in Lobby 7 on a recent morning. \u201cIt\u2019s so powerful. But sometimes it scares me.\u201d\u00a0\nThe founders\u00a0had debated the promise and perils of AI in class and among friends, but their push to reach a wider audience came in September, at a Google-sponsored\u00a0fairness in machine learning workshop\u00a0in Cambridge. There, an MIT professor\u00a0floated the idea of an ethics forum and put the three women in touch.\u00a0\nThen when\u00a0MIT announced plans last month to create the MIT Stephen A. Schwarzman College of Computing, they launched the\u00a0MIT AI Ethics Reading Group. Amid\u00a0the enthusiasm following the Schwarzman announcement, more than 60 people turned up to their first meeting.\u00a0\nOne was Sacha Ghebali, a\u00a0master\u2019s student at the\u00a0MIT Sloan School of Management. He had taken a required ethics course in his finance program at MIT and was eager to learn more.\n\u201cWe\u2019re building tools that have a lot of leverage,\u201d he says. \u201cIf you don\u2019t build them properly, you can do a lot of harm. You need to be constantly thinking about ethics.\u201d\nOn a recent night, Ghebali was among those returning for a second night of discussion. They gathered around a stack of pizza boxes in an empty classroom as Gilpin kicked off the meeting by recapping the fatal crash last spring in which a self-driving Uber struck a pedestrian. Who should be liable, Gilpin asked, the engineer who programmed the car or the person behind the wheel?\nA lively debate followed.\u00a0The students then broke into small groups as the conversation shifted to how ethics should be taught: either as a stand-alone course,\u00a0or integrated throughout the curriculum. They considered two models: Harvard, which embeds philosophy and moral reasoning into its computer science classes, and Santa Clara University, in Silicon Valley, which offers a case study-based module on ethics within its introductory data science courses.\u00a0\nReactions in the room were mixed.\n\u201cIt\u2019s hard to teach ethics in a CS class so maybe there should be separate classes,\u201d one student offered. Others thought ethics should be integrated at each level of technical training.\u00a0\n\u201cWhen you learn to code, you learn a design process,\u201d said Natalie Lao, an EECS graduate student helping to develop AI courses for K-12 students. \u201cIf you include ethics into your design practice you learn to internalize ethical programming as part of your work flow.\u201d\nThe students also debated whether stakeholders beyond the end-user should be considered. \u201cI was never taught when I\u2019m building something to talk to all the people it will effect,\u201d Suresh told the group. \u201cThat could be really useful.\u201d\nHow the Institute should teach ethics in the MIT Schwarzman College of Computing era remains unclear, says Abelson, the Class of 1922 Professor of Computer Science and Electrical Engineering who helped start the group and was at both meetings. \u201cThis is really just the beginning,\u201d he says. \u201cFive years ago, we weren\u2019t even talking about people shutting down the steering wheel of your car.\u201d\nAs AI continues to evolve, questions of safety and fairness will remain a foremost concern. In their research at MIT, the founders of the ethics reading group are simultaneously developing tools to address the dilemmas raised in the group.\u00a0\nGilpin is creating the methodologies and tools to help self-driving cars and other autonomous machines explain themselves. For these machines to be truly safe and widely trusted, she says, they need to be able to interpret their actions and learn from their mistakes.\u00a0\nSuresh is developing algorithms that make it easier for people to use data responsibly. In a summer internship with Google, she looked at how algorithms trained on Google News and other text-based datasets pick up on certain features to learn biased associations. Identifying sources of bias in the data pipeline, she says, is key to avoiding more serious problems in downstream applications.\u00a0\nChen, formerly a data scientist and chief of staff at DropBox, develops machine learning tools for health care. In a new paper,\u00a0Why Is My Classifier Discriminatory, she argues that the fairness of AI predictions should be measured and corrected by collecting more data, not just by tweaking the model. She presents her paper next month at the world\u2019s largest machine-learning conference, Neural Information Processing Systems.\n\u201cSo many of the problems at Dropbox, and now in my research at MIT, are completely new,\u201d she says. \u201cThere isn't a playbook. Part of the fun and challenge of working on AI is that you're making it up as you go.\u201d\nThe AI-ethics group holds its last two meeting of the semester on Nov. 28 and Dec. 12.\n"}, {"source": "MIT", "title": "Rising Stars in EECS supports women in electrical engineering and computer science", "link": "/2018/rising-stars-eecs-supporting-women-electrical-engineering-computer-science-1127", "date": "8", "content": "For women in engineering, getting ahead sometimes means trying to be \u201cone of the guys.\u201d That\u2019s why Margarita Paz Castro says she enjoyed attending Rising Stars in EECS, a workshop held recently at MIT for women interested in academic careers in electrical engineering and computer science.\n\u201cIt\u2019s very empowering being surrounded by women,\u201d said Castro, who earned a master\u2019s degree in Chile before moving to the University of Toronto to do PhD research on discrete optimization problems. \u201cI like to see role models.\u201d\nDesigned to help graduate students and postdocs navigate the early stages of an academic career, the Rising Stars workshop provided participants with practical information and candid advice on seeking and interviewing for faculty jobs, networking, teaching, speaking, mentoring, funding research, setting up labs, getting tenure, and managing day-to-day life in academia.\n\u201cThis is an easy, compact way to get information you can\u2019t get anywhere else. It\u2019s been fabulous,\u201d said Orianna DeMasi, a PhD candidate at the University of California at Berkeley, who is working on an application for machine learning for medicine. \u201cI liked the transparency about the process and the idea that they want everyone to succeed.\u201d\nFounded in 2012 by MIT\u2019s Department of Electrical Engineering and Computer Science (EECS), the workshop has more than doubled in attendance over the years. The 76 women chosen to participate this year were selected from a pool of more than 240 applicants, represent 20 different research areas, and hail from 30 universities and organizations in the United States and several other countries.\n\u201cYou should be very proud. Be super-confident,\u201d Stefanie Mueller, the X-Career Development Assistant Professor in EECS at MIT, said in her opening remarks. Mueller, one of the workshop\u2019s four technical co-chairs, spoke on applying for jobs and moderated a panel on research.\n\u201cPast Rising Stars have been very successful,\u201d said Asu Ozdaglar, the School of Engineering Distinguished Professor of Engineering and EECS department head, who served as workshop chair. She noted that more than 30 percent of Rising Stars in EECS alumni hold faculty positions (including four at MIT), and another 20 percent work in industry; of the rest, the majority are still students or postdocs.\nAnantha P. Chandrakasan, the Vannevar Bush Professor of Electrical Engineering and Computer Science and dean of MIT\u2019s School of Engineering, joined Mueller and Ozdaglar in welcoming attendees to the workshop. Chandrakasan, who founded Rising Stars when he served as head of EECS, noted that in recent years the workshop has been hosted by Stanford University, Carnegie Mellon University, and UC Berkeley. \u201cWe\u2019re very excited that this has gone national,\u201d he said.\nThe Rising Stars concept has also begun expanding to other fields. At MIT, there are now similar programs in aeronautics and astronautics, biomedicine, chemical engineering, civil and environmental engineering, mechanical engineering, and nuclear science and engineering, Chandrakasan said.\nThis year\u2019s Rising Stars in EECS, held Oct. 28-30, began with a Sunday night dinner and reception, included \u00a0two days of talks by more than 40 panelists and speakers, and featured a banquet at the MIT Museum. A workshop highlight was a poster session that gave attendees a chance to pitch their research to faculty.\nNiranjini Rajagopal, a PhD candidate at Carnegie Mellon, for example, presented her work on \u201cA Sensor Fusion Approach to Indoor Localization.\u201d She said it was a nice change to discuss her work with an audience of engineers outside her narrow specialty. \u201cIt\u2019s also nice to see what everyone else is working on,\u201d she said.\nIn general, the workshop centered on topics that would have been equally relevant to male academics, such as \u201cHow to Apply for Faculty Jobs,\u201d \u201cTeaching,\u201d and \u201cMentoring Students.\u201d However, at several points the special challenges women face became apparent.\nOne attendee told a story of facing pushback from a male student who persistently challenged her grasp of the material she was teaching. Another said she noticed a woman who was doing well in her class left when the only other woman enrolled dropped out.\nAnette \u201cPeko\u201d Hosoi, associate dean of engineering and the Neil and Jane Pappalardo Professor of Mechanical Engineering at MIT, said she has faced similar situations. For instance, she once met with a male student who had not done well on an exam in her mechanics class. He admitted being embarrassed by his performance, saying: \u201cI even looked at the person next to me and realized I got beat by a girl.\u201d\nIdeas for addressing such challenges varied. Professor Randall Davis of EECS and the Computer Science and Artificial Intelligence Lab (CSAIL), who gave a talk on \u201cHow to Speak,\u201d fielded the question about the male student who challenged his professor in class. Davis suggested firmly ending the discussion with a redirect to the day\u2019s material. \u201cPeople have said women get ignored. I think a little subtle pushback is warranted,\u201d he said.\n\u201cBeing visible is really important,\u201d said Hosoi, who gave a talk on teaching. \u201cWhen Mary Boyce was head of mechanical engineering, she selected women to teach the intro mechanics class,\u201d ensuring that men get used to women faculty early on.\u00a0\nBeing in the minority can have its perks, however. \u201cSometimes, as women, it\u2019s an advantage that we\u2019re rare in our departments,\u201d said Jaime Teevan, chief scientist for Microsoft Experiences and Devices and affiliate professor at the University of Washington, who moderated the panel discussion on career trajectories. \u201cAt cocktail parties, people will remember your name because there are not many women there.\u201d\nSpeakers also noted that female faculty are often flooded with requests to serve on committees and as conference organizers, because they provide diversity. \u201cI was asked to be on conference committees five to 10 times a year. Male colleagues were maybe on one,\u201d said Virginia Vassilevska Williams, the Steven G. (1968) and Renee Finn Career Development Associate Professor in EECS and a Rising Stars technical co-chair. Williams moderated a panel on search committees and the \u201cToward Tenure\u201d discussion.\nChoosing which commitments to prioritize comes with the job, faculty members said.\n\u201cI think academic jobs are associated with learning to say \u2018no\u2019 a lot,\u201d said Polina Golland, the Henry Ellis Warren (1894) Professor of EECS and a CSAIL principal investigator, who worked with Chandrakasan to launch the first Rising Stars workshop in 2012. She participated in a session titled \u201cWords of Wisdom\u201d with four other leading MIT professors of EECS, including Dina Katabi, Muriel Medard, Daniela Rus, and moderator Ronitt Rubinfeld. \u201cI recently learned the phrase \u2018I regretfully decline,\u2019\u201d Golland said wryly. \u201cFeel free to use it.\u201d\nThe road to an academic career is not always direct, as attendees learned in the opening session on career trajectories. Ranjitha Kumar, an assistant professor of computer science at the University of Illinois at Urbana-Champaign, launched a company before going into academia. Azita Emami worked at an IBM research lab before joining the Caltech, where she is now the Andrew and Peggy Cherng Professor of Electrical Engineering and Medical Engineering.\nChallenges to academic success \u2014 and happiness \u2014 include the \u201ctwo-body problem\u201d of landing a job as an academic with an academic spouse, as well as deciding when to have children and finding the right mentors, panelists and speakers said. The best way to navigate all these challenges is with a lot of support \u2014 from friends, family, colleagues, and advisors.\n\u201cYour support system is very important,\u201d said Rus, the Andrew (1956) and Erna Viterbi Professor of EECS and director of CSAIL at MIT. \u201cIf you have support, you can have it all.\u201d\nBuilding that support network is what Rising Stars is all about, Ozdaglar said. She told the young women in the room: \u201cOur hope is that this peer network that you create will support you throughout your careers.\u201d\nIn addition to Mueller and Williams, the event\u2019s technical co-chairs included EECS Assistant Professor Farnaz Niroui and Associate Professor Vivienne Sze (both alumnae of earlier Rising Stars events). Niroui moderated the job-search panel, while Sze moderated the \u201cToward Tenure\u201d discussion. Ozdaglar served as workshop chair, while Chandrakasan was the workshop advisor.\nVisit the Rising Stars in EECS 2018 website for bios of all 76 participants, the schedule of speakers and panelists, and links to websites for earlier workshops.\n"}, {"source": "MIT", "title": "Remembering Professor Emeritus Alan McWhorter, 1930-2018", "link": "/2018/remembering-mit-professor-emeritus-alan-mcwhorter-1121", "date": "8", "content": "Alan L. McWhorter, a longtime professor in MIT\u2019s Department of Electrical Engineering and Computer Science (EECS) and an administrator and researcher at MIT Lincoln Laboratory, has died in New Orleans, Louisiana. He was 87.\nHis family said his death was unexpected despite some recent health problems. A memorial service will be held at a later date.\nMcWhorter is best known for his research in electronic and quantum devices including transistors, lasers, and masers. In 1955, he developed the McWhorter model for low-frequency flicker (or 1/f) noise caused by surface effects in semiconductor devices. The model, sometimes called \u201cthe McWhorter effect,\u201d continues to be widely cited today. In the mid-1960s, he received three patents related to semiconductors.\nHowever, according to MIT colleague Paul Penfield Jr., his range of interests was broader and extended in many dimensions. \u201cAl\u2019s lesser-known but still pioneering work included aspects of control systems, power semiconductors, infrared detection, and optical communications,\u201d said Penfield, an emeritus professor and former EECS department head. \u201cBut besides his technical breadth, he understood both the theoretical and experimental sides of engineering, cared about both the pedagogy and applications of various technologies, and promoted short-term applied research along with long-range curiosity-driven research.\u201d\nLong legacy at MIT \nBorn in Crowley, Louisiana, on Aug. 25, 1930, McWhorter began his education in New Orleans at Tulane University\u2019s School of Engineering, then transferred to the University of Illinois at Urbana-Champaign, receiving a bachelor\u2019s degree in electrical engineering in 1951. He received an ScD degree in electrical engineering from MIT in 1955.\nMcWhorter joined the MIT Department of Electrical Engineering as an assistant professor in 1959, served as an associate professor from 1960 to 1966, and as a full professor until he retired in 1996. During his time with EE (now EECS), he supervised more than 30 students\u2019 work on their master\u2019s, PhD, and ScD theses. With a generous donation, he established a fellowship fund, the Alan L. McWhorter (1955) Fund, to support graduate students studying electrical engineering\nMcWhorter was also affiliated with the Solid State Division at MIT Lincoln Laboratory for more than 40 years, beginning as a staff member in 1955. He served as assistant division head and associate head between 1962 and 1965, when he was named to head the division. He served as division head for 29 years, becoming a Lincoln Laboratory Fellow in 1994 and retiring in 1996.\n\u201cAl was a warm, generous, and inspiring colleague,\u201d recalled Erich Ippen, a principal investigator at MIT\u2019s Research Laboratory of Electronics (RLE) and a professor emeritus of both electrical engineering and physics. \u201cAs an early leader in quantum electronics, he was a valuable mentor for us younger researchers in that area on campus as well as at Lincoln Lab.\u201d\u00a0\nFrederick Leonberger knew McWhorter in both MIT roles. \u201cI had the good fortune of having Al as my doctoral thesis advisor. His insightful guidance and high standards not only inspired me in my research, but also provided an excellent model for conducting and managing the research process,\u201d said Leonberger, who is now a principal with EOvation Advisors. \u201cAt Lincoln Laboratory, where I subsequently worked, his leadership \u2014 as well as the range of research topics he had expertise in and contributed to \u2014 provided a role model of technical excellence for the staff, and helped enable the many important technical achievements of the division over the years.\u201d\nMany MIT colleagues still recall that, in 1969, McWhorter was involved in a near-fatal collision in Arlington, Massachusetts, sustaining a skull fracture, a concussion, eye and facial injuries, and many broken bones. But four months later, after seven operations and multiple setbacks, he walked out of Massachusetts General Hospital, returning to work at MIT soon after. He also returned to hiking and mountain-climbing, beginning with a trip to the Grand Tetons one year after his release from the hospital.\nPatent particulars \nMcWhorter received his first two patents, both for semiconductor switching matrixes, in 1963 and 1964, at a time when researchers were experimenting with a variety of ways for using semiconductors in computers. The patents describe the development of the cryosar, one of the early semiconductor memory devices. Semiconductor memory (such as RAM) is now ubiquitous in electronics.\nThe third, and arguably most historically significant patent, came in 1966. It reflected McWhorter\u2019s involvement as a member of one of three teams that had nearly simultaneously demonstrated the first semiconductor laser (then called an infrared maser). Today, semiconductor lasers are used in devices ranging from DVD players to laser pointers to printers to tattoo-removal devices.\nProfessional recognition \nIn 1958, McWhorter and two colleagues received the National Electronics Conference Annual Award for their technical paper on solid-state masers.\nMcWhorter was also a long-time member of the IEEE, a leading technical professional organization. In 1968, he was named an IEEE Fellow, a distinction reserved for select members with extraordinary accomplishments. The IEEE recognized McWhorter \u201cfor contributions to control theory and its applications to switch power systems and image processing.\u201d In 1971, McWhorter received the IEEE David Sarnoff Award, which recognizes exceptional work in electronics, \u201cfor outstanding contributions leading to a better understanding of semiconductor devices.\u201d In 2000, he won an IEEE Third Millennium Medal \u201cfor contributions to control theory and its applications to switch power systems and image processing.\u201d He was one of just 45 members of the IEEE Electron Devices Society to be so honored.\nIn 1993, he was elected to the National Academy of Engineering for \u201coutstanding research and technical leadership in the fields of quantum electronics and solid-state devices.\u201d He was also a long-time fellow of the American Physical Society, and a member of the scientific and engineering societies Sigma Xi, Tau Beta Pi, and Eta Kappa Nu (HKN).\nMcWhorter also authored or co-authored dozens of scientific articles and hundreds of reports, contributed to several books, and served as an editor on two IEEE publications.\nProfessor emeritus \nAfter retiring in 1996, he returned to the New Orleans area and again began participating in Tulane activities, such as the Friends of Music, the Summer Lyric Theatre, and the Emeritus Club and Educational Conference offerings of the Alumni House. McWhorter, who died on July 11, 2018, is survived in the New Orleans area by niece Patricia McWhorter\u00a0(Peter C. Broussard); nephews David McWhorter (Lisa) and Steven McWhorter (Renee), and six grandnieces: Olivia Broussard (Lucien Weiss);\u00a0 Allyson McWhorter; Brindley McWhorter; Rebecca McWhorter Ruegge (Gene); Elizabeth McWhorter Guillory (Dakota); and Emily McWhorter Menendez (Colin). A private memorial service will be held in New Orleans at a later date.\nGifts in memory of Alan McWhorter may be made to MIT via the\u00a0Alan L.\u00a0McWhorter\u00a0(1955) Fund, account #3304350.\u00a0Credit-card gifts can be made at giving.mit.edu/alan-mcwhorter. Checks should be made payable to MIT and mailed to: MIT Memorial Gifts Office, 600 Memorial Drive, Room W98-500, Cambridge, MA 02139.\n"}, {"source": "MIT", "title": "Sixteen grad students named to the Siebel Scholars class of 2019 ", "link": "/2018/mit-16-graduate-students-named-2019-siebel-scholars-1120", "date": "8", "content": "Sixteen MIT graduate students are among the 2019 cohort of Siebel Scholars hailing from the world\u2019s top graduate programs in bioengineering, business, computer science, and energy science. They were recognized at a luncheon and awards ceremony on Nov. 13.\nHonored for their academic achievements, leadership, and commitments to addressing crucial global challenges, the select MIT students are among 96 students from 16 leading institutions that participate in the program.\nSiebel Scholars each receive an award of $35,000 to cover their final year of study. In addition, they will join a community of more than 1,200 past Siebel Scholars, including more than 245 from MIT, who serve as advisors to the Thomas and Stacy Siebel Foundation and collaborate \u201cto find solutions to society\u2019s most pressing problems,\u201d according to the foundation.\nMIT\u2019s 2019 Siebel Scholars, selected by the deans of their respective schools, include:\nDaniel Barnes, MIT Sloan School of Management\nRyan Bradley, MIT Sloan School of Management\nNichole Clarke, Department of Electrical Engineering and Computer Science\u00a0\nBreanna DiAndreth, Department of Biological Engineering\nClaire Duvallet, Department of Biological Engineering\nLogan Engstrom, Department of Electrical Engineering and Computer Science\u00a0\nAlireza Fallah, Department of Electrical Engineering and Computer Science\u00a0\nLinyi Gao, Department of Biological Engineering\nManu Kumar, Department of Biological Engineering\nYancan \u201cLydia\u201d\u00a0Li, MIT Sloan School of Management\nJames Mawdsley, Department of Electrical Engineering and Computer Science\u00a0\nAndrew Mullen, Department of Electrical Engineering and Computer Science\u00a0\nAlyssa Murray, MIT Sloan School of Management\nGregory O\u2019Sullivan, MIT Sloan School of Management\nIan Schneider, Institute for Data, Systems, and Society\nAsmamaw Wassie, Department of Biological Engineering\nEstablished by the Siebel Foundation in 2000, the Siebel Scholars program provides grants to outstanding students at top graduate schools in the United States, China, France, Italy, and Japan.\n"}, {"source": "MIT", "title": "I think, therefore I code", "link": "/2018/student-jessy-lin-computer-science-philosophy-1116", "date": "8", "content": "To most of us, a 3-D-printed turtle just looks like a turtle; four legs, patterned skin, and a shell. But if you show it to a particular computer in a certain way, that object\u2019s not a turtle \u2014 it\u2019s a gun.\nObjects or images that can fool artificial intelligence like this are called adversarial examples. Jessy Lin, a senior double-majoring in computer science and electrical engineering and in philosophy, believes that they\u2019re a serious problem, with the potential to trip up AI systems involved in driverless cars, facial recognition, or other applications. She and several other MIT students have formed a research group called LabSix, which creates examples of these AI adversaries in real-world settings \u2014 such as the turtle identified as a rifle \u2014 to show that they are legitimate concerns.\nLin is also working on a project called Sajal, which is a system that could allow refugees to give their medical records to doctors via a QR code. This \u201cmobile health passport\u201d for refugees was born out of VHacks, a hackathon organized by the Vatican, where Lin worked with a team of people she\u2019d met only a week before. The theme was to build something for social good \u2014 a guiding principle for Lin since her days as a hackathon-frequenting high school student.\n\u201cIt\u2019s kind of a value I\u2019ve always had,\u201d Lin says. \u201cTrying to be thoughtful about, one, the impact that the technology that we put out into the world has, and, two, how to make the best use of our skills as computer scientists and engineers to do something good.\u201d\nClearer thinking through philosophy\nAI is one of Lin\u2019s key interests in computer science, and she\u2019s currently working in the Computational Cognitive Science group of Professor Josh Tenenbaum, which develops computational models of how humans and machines learn. The knowledge she\u2019s gained through her other major, philosophy, relates more closely this work than it might seem, she says.\n\u201cThere are a lot of ideas in [AI and language-learning] that tie into ideas from philosophy,\u201d she says. \u201cHow the mind works, how we reason about things in the world, what concepts are. There are all these really interesting abstract ideas that I feel like \u2026 studying philosophy surprisingly has helped me think about better.\u201d\nLin says she didn\u2019t know a lot about philosophy coming into college. She liked the first class she took, during her first year, so she took another one, and another \u2014 before she knew it,\u00a0she was hooked. It started out as a minor; this past spring, she declared it as a major.\n\u201cIt helped me structure my thoughts about the world in general, and think more clearly about all kinds of things,\u201d she says.\nThrough an interdisciplinary class on ethics and AI ethics, Lin realized the importance of incorporating perspectives from people who don\u2019t work in computer science. Rather than writing those perspectives off, she wants to be someone inside the tech field who considers issues from a humanities perspective and listens to what people in other disciplines have to say.\nTeaching computers to talk\nComputers don\u2019t learn languages the way that humans do \u2014 at least, not yet. Through her work in the Tenenbaum lab, Lin is trying to change that.\nAccording to one hypothesis, when humans hear words, we figure out what they are by first saying them to ourselves in our heads. Some computer models aim to recreate this process, including recapitulating the individual sounds in a word. These \u201cgenerative\u201d models do capture some aspects of human language learning, but they have other drawbacks that make them impractical for use with real-world speech.\nOn the other hand, AI systems known as neural networks, which are trained on huge sets of data, have shown great success with speech recognition. Through several projects, Lin has been working on combining the strengths of both types of models, to better understand, for example, how children learn language even at a very young age.\nUltimately, Lin says, this line of research could contribute to the development of machines that can speak in a more flexible, human way.\nHackathons and other pastimes\nLin first discovered her passion for computer science at Great Neck North High School on Long Island, New York, where she loved staying up all night to create computer programs during hackathons. (More recently, Lin has played a key role in HackMIT, one of the Institute\u2019s flagship hackathons. Among other activities, she helped organize the event from 2015 to 2017, and in 2016 was the director of corporate relations and sponsorship.) It was also during high school that she began to attend MIT Splash, a program hosted on campus offering a variety of classes for K-12 students.\n\u201cI was one of those people that always had this dream to come to MIT,\u201d she says.\nLin says her parents and her two sisters have played a big role in supporting those dreams. However, her knack for artificial intelligence doesn\u2019t seem to be genetic.\n\u201cMy mom has her own business, and my dad is a lawyer, so \u2026 who knows where computer science came out of that?\u201d she says, laughing.\nIn recent years, Lin has put her computer science skills to use in a variety of ways. While in high school, she interned at both New York University and Columbia University. During Independent Activities Period in 2018, she worked on security for Fidex, a friend\u2019s cryptocurrency exchange startup. The following summer she interned at Google Research NYC on the natural language understanding team, where she worked on developing memory mechanisms that allow a machine to have a longer-term memory. For instance, a system would remember not only the last few phrases it read in a book, but a character from several chapters back. Lin now serves as a campus ambassador for Sequoia Capital, supporting entrepreneurship on campus.\nShe currently lives in East Campus, where she enjoys the \u201cvery vibrant dorm culture.\u201d Students there organize building projects for each first-year orientation \u2014\u00a0when Lin arrived, they built a roller coaster. She\u2019s helped with the building in the years since, including a geodesic dome that was taller than she is. Outside of class and building projects, she also enjoys photography.\nUltimately, Lin\u2019s goal is to use her computer science skills to benefit the world. About her future after MIT, she says, \u201cI think it could look something like trying to figure out how we can design AI that is increasingly intelligent but interacts with humans better.\u201d\n"}, {"source": "MIT", "title": "Putting food-safety detection in the hands of consumers", "link": "/2018/food-safety-rfid-detection-consumers-1114", "date": "8", "content": "MIT Media Lab researchers have developed a wireless system that leverages the cheap RFID tags already on hundreds of billions of products to sense potential food contamination \u2014 with no hardware modifications needed. With the simple, scalable system, the researchers hope to bring food-safety detection to the general public.\nFood safety incidents have made headlines around the globe for causing illness and death nearly every year for the past two decades. Back in 2008, for instance, 50,000 babies in China were hospitalized after eating infant formula adulterated with melamine,\u00a0an organic compound used to make plastics, which is toxic in high concentrations. And this April, more than 100 people in Indonesia died from drinking alcohol contaminated, in part, with methanol, a toxic alcohol commonly used to dilute liquor for sale in black markets around the world.\nThe researchers\u2019 system, called RFIQ, includes a reader that senses minute changes in wireless signals emitted from RFID tags when the signals interact with food. For this study they focused on baby formula and alcohol, but in the future, consumers might have their own reader and software to conduct food-safety sensing before buying virtually any product. Systems could also be implemented in supermarket back rooms or in smart fridges to continuously ping an RFID tag to automatically detect food spoilage, the researchers say.\nThe technology hinges on the fact that certain changes in the signals emitted from an RFID tag correspond to levels of certain contaminants within that product. A machine-learning model \u201clearns\u201d those correlations and, given a new material, can predict if the material is pure or tainted, and at what concentration. In experiments, the system detected baby formula laced with melamine with 96 percent accuracy, and alcohol diluted with methanol with 97 percent accuracy.\n\u201cIn recent years, there have been so many hazards related to food and drinks we could have avoided if we all had tools to sense food quality and safety ourselves,\u201d says Fadel Adib, an assistant professor at the Media Lab who is co-author on a paper describing the system, which is being presented at the ACM Workshop on Hot Topics in Networks. \u201cWe want to democratize food quality and safety, and bring it to the hands of everyone.\u201d\nThe paper\u2019s co-authors include: postdoc and first author Unsoo Ha, postdoc Yunfei Ma, visiting researcher Zexuan Zhong, and electrical engineering and computer science graduate student Tzu-Ming Hsu.\n\n\n\n\n MIT Media Lab \n\n\nThe power of \u201cweak coupling\u201d\nOther sensors have also been developed for detecting chemicals or spoilage in food. But those are highly specialized systems, where the sensor is coated with chemicals and trained to detect specific contaminations. The Media Lab researchers instead aim for broader sensing. \u201cWe\u2019ve moved this detection purely to the computation side, where you\u2019re going to use the same very cheap sensor for products as varied as alcohol and baby formula,\u201d Adib says.\nRFID tags are stickers with tiny, ultra-high-frequency antennas. They come on food products and other items, and each costs around three to five cents. Traditionally, a wireless device called a reader pings the tag, which powers up and emits a unique signal containing information about the product it\u2019s stuck to.\nThe researchers\u2019 system leverages the fact that, when RFID tags power up, the small electromagnetic waves they emit travel into and are distorted by the molecules and ions of the contents in the container. This process is known as \u201cweak coupling.\u201d Essentially, if the material\u2019s property changes, so do the signal properties.\nA simple example of feature distortion is with a container of air versus water. If a container is empty, the RFID will always respond at around 950 megahertz. If it\u2019s filled with water, the water absorbs some of the frequency, and its main response is around only 720 megahertz. Feature distortions get far more fine-grained with different materials and different contaminants. \u201cThat kind of information can be used to classify materials \u2026 [and] show different characteristics between impure and pure materials,\u201d Ha says.\nIn the researchers\u2019 system, a reader emits a wireless signal that powers the RFID tag on a food container. Electromagnetic waves penetrate the material inside the container and return to the reader with distorted amplitude (strength of signal) and phase (angle).\nWhen the reader extracts the signal features, it sends those data to a machine-learning model on a separate computer. In training, the researchers tell the model which feature changes correspond to pure or impure materials. For this study, they used pure alcohol and alcohol tainted with 25, 50, 75, and 100 percent methanol; baby formula was adulterated with a varied percentage of melamine, from 0 to 30 percent.\n\u201cThen, the model will automatically learn which frequencies are most impacted by this type of impurity at this level of percentage,\u201d Adib says. \u201cOnce we get a new sample, say, 20 percent methanol, the model extracts [the features] and weights them, and tells you, \u2018I think with high accuracy that this is alcohol with 20 percent methanol.\u2019\u201d\n\u201cThis is certainly a very inventive use of RFID-like technology, and could have strong impact in a number of real industries related to food and health,\u201d says Ben Zhao, a professor of computer science at the University of Chicago. While the system needs to be further evaluated for accuracy for real-world applications, \u201cit is clear that current results show promise. [The work] may well be the beginning of significant work in this space, and continued development along this direction may completely change the way we evaluate food quality in the future.\u201d\nBroadening the frequencies\nThe system\u2019s concept derives from a technique called radio frequency spectroscopy, which excites a material with electromagnetic waves over a wide frequency and measures the various interactions to determine the material\u2019s makeup.\nBut there was one major challenge in adapting this technique for the system: RFID tags only power up at a very tight bandwidth wavering around 950 megahertz. Extracting signals in that limited bandwidth wouldn\u2019t net any useful information.\nThe researchers built on a sensing technique they developed earlier, called two-frequency excitation, which sends two frequencies \u2014 one for activation, and one for sensing \u2014 to measure hundreds more frequencies. The reader sends a signal at around 950 megahertz to power the RFID tag. When it activates, the reader sends another frequency that sweeps a range of frequencies from around 400 to 800 megahertz. It detects the feature changes across all these frequencies and feeds them to the reader.\n\u201cGiven this response, it\u2019s almost as if we have transformed cheap RFIDs into tiny radio frequency spectroscopes,\u201d Adib says.\nBecause the shape of the container and other environmental aspects can affect the signal, the researchers are currently working on ensuring the system can account for those variables. They are also seeking to expand the system\u2019s capabilities to detect many different contaminants in many different materials.\n\u201cWe want to generalize to any environment,\u201d Adib says. \u201cThat requires us to be very robust, because you want to learn to extract the right signals and to eliminate the impact of the environment from what\u2019s inside the material.\u201d\n"}, {"source": "MIT", "title": "Bridge to the future of engineering", "link": "/2018/bridge-to-the-future-of-engineering-1111", "date": "8", "content": "School of Engineering faculty are embracing the new MIT Stephen A. Schwarzman College of Computing as a bold response to the rapid evolution of computing that is altering and, in many cases, fundamentally transforming their disciplines.\nInspired by student interest in computing, MIT President L. Rafael Reif launched an assessment process more than a year ago that involved widespread engagement with key stakeholders across the MIT community. Discussions were led by President Reif, Provost Martin A. Schmidt, and Dean of the School of Engineering Anantha P. Chandrakasan with Faculty Chair Susan Silbey playing a key role.\n\u201cThe creation of the college is MIT\u2019s first major academic structural change since 1950,\u201d says Chandrakasan, the Vannevar Bush Professor of Electrical Engineering and Computer Science. \u201cAfter consulting with faculty from across engineering and throughout MIT, the need to do something timely and deeply impactful was abundantly clear. Mr. Schwarzman\u2019s inspired and amazingly generous support was instrumental to our ability to move forward.\u201d\nThe school\u2019s eight department heads and two institute directors recently spoke of the exciting possibilities ahead as the college, which represents a $1 billion commitment, gets underway. There will be a new building, a new dean, and 50 new faculty positions located within the college and jointly with other departments across MIT.\nSchool leadership says the college meets a significant need partly because it directly aligns with recent activities and changes in some of their own practices. For example, many departments have adapted their hiring and recruitment practices to include a heavier emphasis on selecting faculty who can work at a high level in computation along with another specialized field, says Chandrakasan. \u201cIn some ways the change has arrived,\u201d he says. \u201cThe college is our way of building a powerful framework and environment for research and collaborations that involve computing and that are occurring across disciplines. The college remains a young idea and its vibrancy and success will depend on thoughtful input from people across MIT, which I look forward to hearing.\u201d\nAt the forefront\nThe eye of the storm of change has undoubtedly been in the Department of Electrical Engineering and Computer Science (EECS). Faculty do research to advance core computing topics while also addressing an inundation of requests to build bridges and connect their work with other disciplines. In the last two years alone, EECS faculty have established new joint academic programs with economics and urban science and planning.\nThe creation of the college will provide vital support and accelerate all kinds of computing-related research and learning that is happening across the Institute, says Asu Ozdaglar, School of Engineering Distinguished Professor of Engineering and EECS department head. \u201cWith the launch of the college, we hope that MIT\u2019s leading position in research and the education of future leaders in computing will continue and grow.\u201d\nMarkus Buehler, head of the Department of Civil and Environmental Engineering and the McAfee Professor of Engineering, agrees. \u201cWe have been at the forefront of this transformation of our discipline,\u201d he says. The increased role of computing has impacted all five of CEE\u2019s strategic focus areas, which include ecological systems, resources, structures and design, urban systems, and global systems. As a result, the department is now planning a potential new major between CEE and computer science, and the college will help in that effort, says Buehler. \u201cThe creation of the college will serve as a key enabler,\u201d he says.\nThe MIT Institute for Data, Systems, and Society is also deeply aligned with the college, says Munther Dahleh, director of IDSS and the William A. Coolidge Professor of Electrical Engineering and Computer Science. IDSS works with all five schools to promote cross-cutting education and research to advance data science and information and decision systems in order to address societal challenges in a systematic and rigorous manner. IDSS plays a \u201cbridge\u201d role that will prove useful to the college, Dahleh says. It has launched cross-disciplinary academic programs, hired joint faculty in three schools, and enabled collaborations across all five schools.\n\u201cThe new college will provide a structure for expanding these activities, he says. \u201cAnd it will create new opportunities to connect with a larger community in sciences, social science, and urban planning and architecture.\u201d\nSteeped in computing\nThe timing is right for the college, say the faculty. \u201cWe are excited by the growth opportunities in computing because the nuclear science and engineering disciplines are so steeped in the development and application of numerical tools,\u201d says Dennis Whyte, the Hitachi America Professor of Engineering and head of the Department of Nuclear Science and Engineering.\nThe Department of Aeronautics and Astronautics has\u00a0a significant number of faculty working in information engineering for aerospace systems, particularly autonomous systems, says Daniel Hastings, the Cecil and Ida Green Education Professor at MIT and incoming head of the department.\n\u201cThe college will allow us to expand our research and teaching into all the ways that computing technologies are changing the aerospace enterprise,\u201d says Hastings. Those ways include deep learning to recognize patterns for maintenance in the operation of multiple aircraft, artificial intelligence for traffic control of fleets of uninhabited flying vehicles, and intelligent robotic systems in space to service low-Earth orbit satellites, among others.\nIncreasingly, the tools of machine learning and artificial intelligence are being fruitfully applied to materials design problems, says Christopher A. Schuh, the Danae and Vasilis Salapatas Professor of Metallurgy and head of the Department of Materials Science and Engineering (DMSE). \u201cOur department sees computational thinking as a critical skill set for any budding materials scientist,\u201d he says, adding a large fraction of DMSE faculty focus on computational materials science or use computational methods in designing new materials.\n\u201cWe are excited to see MIT focusing on computing broadly, and we look forward to a deep materials-centric engagement with the college,\u201d he says.\nGrowth opportunities \nPaula Hammond, the David H. Koch Professor in Engineering and head of the Department of Chemical Engineering, would like to see the college provide new opportunities and pathways for chemical engineering to grow. One-third of faculty in her department work with computation as their primary research method, she says.\nHammond looks forward especially to the arrival of new faculty. \u201cI see these new positions as a chance to hire faculty members who are rooted in the molecular and systems-oriented thinking that defines our field, while doing research in new and important areas, including global problems in environment, energy, health, and water.\u201d She says such interdisciplinary faculty would be instrumental in building a new computational major in chemical engineering (10-ENG) that is currently in development.\nDouglas Lauffenburger, the Ford Professor of Bioengineering and head of MIT\u2019s Department of Biological Engineering, expresses a similar hope. \u201cThe creation of the college is a bold step, and I'm hopeful that some of these additional faculty positions will enable a strengthening of computational biology on campus.\u201d\nTraining the next generation\nFaculty also spoke of how the college will enable MIT students to play leadership roles in the future of computing \u2014 and other engineering fields. \u201cIt will strengthen our ability to train the next generation of mechanical engineers and better prepare students to join the workforce by exposing them to computation and AI throughout their education,\u201d says Evelyn N. Wang, the Gail E. Kendall Professor and head of the Department of Mechanical Engineering.\nAn increasing number of research fields within mechanical engineering rely on computing technologies \u2014 from smarter autonomous machines to more accurate extreme event prediction and -3D printing. \u201cThe college will help students and researchers working in these fields advance their groundbreaking research even further,\u201d adds Wang.\nElazer Edelman, the director of the Institute for Medical Engineering and Science, says the potential is vast. \u201cFrom access to critical data sets to insights derived from machine and deep learning, the college will enable all of us to better interact as a community to address important problems and to train the next batch of young stars at the interface of science, engineering, computing and medicine,\u201d he says. Edelman is the Edward J. Poitras Professor of Medical Engineering and Science at MIT.\n\u201cWe at IMES are particularly excited to work with the college in interacting as a global community of scholars from this incredibly exciting and imaginative platform,\u201d he says.\n"}, {"source": "MIT", "title": "The many interfaces of computing", "link": "/2018/mit-superurop-projects-show-future-of-computing-1111", "date": "8", "content": "The new MIT Stephen A. Schwarzman College of Computing will incorporate the modern tools of computing into disciplines across the Institute. \u201cThe college will equip students to be as fluent in computing and AI [artificial intelligence] as they are in their own disciplines \u2014\u00a0and ready to use these digital tools wisely and humanely to help make a better world,\" says MIT President Rafael Reif.\nAs often happens, it appears MIT students are already there. We recently spoke with six undergraduate students who are participating in the Advanced Undergraduate Research Opportunities Program (SuperUROP), and found them already thinking deeply about how new computational technologies can be put to use in fields outside of computer science. These students are working on a huge range of problems that share a common theme: Solving them will provide tangible benefits to society.\nHaripriya Mehta is working to augment human creativity by using machine learning algorithms to provide potential storylines and helpful drawings for blocked artists. Upon arrival at MIT, Mehta knew she wanted to focus on assistive technology to help people. She was originally interested in prosthetics but soon realized there are more ways than one to assist people.\n\u201cI\u2019ve always been a raconteur of sorts, whether it's writing or dancing or playing the piano, and the idea of creative blocks has always interested me,\u201d says Mehta, a third-year student in electrical engineering and computer science. \u201cI want to explore how we can use deep learning to assist artists when we are sort of lost. It would be almost as if you're having a conversation with another artist but instead of an artist, it's a neural net.\u201d\nMehta described widespread application of such a machine learning model: storyboarding for artists; a creative task for elderly to stave off early onset Alzheimer\u2019s; an early childhood education tool to help children form sentences, create stories, and draw.\nSenior Christabel Jemutai Sitienei is seeking to drive financial inclusion in East Africa through artificial intelligence. Growing up she witnessed the mobile money industry spread across Kenya and fuel economic growth. More than 75 percent of adults in Kenya were able to open a bank account because of it. Now Sitienei wants to help Kenyans gain access to additional financial services and heightened business acumen.\n\u201cBorn and bred in Kenya, and with my exposure to AI, I\u2019m in a unique and privileged position to understand the problem,\u201d she says. \u201cI would like to design an app that informs decision making and saves money. It would change how people are building infrastructure and deploying resources.\u201d\nSitienei came to MIT intent on studying mechanical or systems engineering. All that changed in her sophomore year when she developed a mobile app to help her parents in Kenya run their farm.\n\u201cWhen I started using my computing knowledge to solve my own problems, I just knew this was for me,\u201d says Sitienei, who adopted electrical engineering and computer science (EECS) as a major. \u201cThe application I built for my parents has been so valuable to them even until now. I learned that I really like solving problems that I can relate to,\u201d she says.\nGabe Margolis is developing machine learning methods for fast and accurate prediction of seafloor feature maps based on sparse data collected by autonomous underwater vehicles.\nA third-year student in aeronautics and astronautics, Margolis knew from the outset he wanted to focus on cognitive robotics at MIT. He soon realized that EECS was not his only option. \u201cIt seems like the major that best represents my interests would be computer science \u2014 but there's actually a big application of artificial intelligence and autonomous systems in aerospace too,\u201d he says.\n\u201cI realized the artificial intelligence aspects of aerospace engineering are really about exploring the unknown and that is something I think is really cool,\u201d says Margolis.\nMathematics major Andy Wei is tackling machine learning and security. Wei, a fourth-year student, is combining his math and computer science skills to address things like data poisoning, which occurs when attackers inject a small amount of adversarial training data to compromise a neural network.\n\u201cIf we're deploying neural networks, we better have a good understanding of how they are vulnerable to adversarial examples,\u201d he says, describing the risks posed by inputs that are misclassified by the network but indistinguishable from natural data to the human eye.\n\u201cIf people can somehow toy with the system and make some tweaks and the machine fails, that\u2019s an important security issue to understand. I\u2019m really excited to tackle the problem.\u201d\nAnd\u00a0Mattie Wasiak is applying data analytics to health care. She is leveraging clinical data sets to optimize oxygen delivery to newborns. \u201cI am excited to continue pursuing health care applications,\u201d says Wasiak, a third-year student in electrical engineering and computer science.\n\u201cSince freshman year, I've been really interested in machine learning. I\u2019ve been trying to determine what field exactly I want to apply it to,\u201d she says.\nWasiak explored marketing and political science before landing on health care last semester. \u201cI just felt like health care really resonated with me because you can see how a machine learning model that you produce can be used in the field and have an impact on people.\u201d\nFor more information \u2014 and lots of other remarkable examples \u2014 visit the SuperUROP website.\n"}, {"source": "MIT", "title": "Improving materials from the nanoscale up", "link": "/2018/improving-materials-at-nanoscale-materials-day-symposium-1108", "date": "8", "content": "The 2018 MIT Materials Research Laboratory (MRL) Materials Day Symposium, highlighting advances in materials science and engineering, took place in Kresge Auditorium on Oct. 10.\nAmong the latest advances shared: Powerful new combinations of X-rays, electrical probes, and analytical computing that are yielding insights into problems as diverse as fatigue in steel and stability in solar cells.\n\u201cFatigue in steel is a major issue; you don\u2019t see any changes in the shape of your material, and suddenly it fails,\" MIT Assistant Professor C. Cem Ta\u015fan said at the event. \u201cWe are putting a lot of effort in maintenance and safety, yet still we have devastating accidents,\u201d he said, recalling the airline incident in April 2018 when a jet engine turbine blade broke apart and shrapnel from the engine broke a plane window fatally injuring a passenger.\n\u201cThe airline company basically said that component passed all the maintenance requirements. So it was checked, and they couldn\u2019t see any kind of fatigue cracks in it,\u201d Ta\u015fan, the Thomas B. King Career Development Professor of Metallurgy, explained. Ta\u015fan is developing new steel and other metal alloys that are safer, stronger and lighter than those currently available.\nFailure in metals is a complex mix of cracks and other changes in the microstructure caused by temperature, bending, stretching, compression and other forces, but most can survive at most one of these impacts before unleashing a cascade of subtle changes that ultimately result in failure.\nDesign for repair\nTa\u015fan outlined progress on a vanadium-based alloy that changes back to its original state when stress is taken away, and a new type of steel that can be transformed back to its original state when heat is applied. Stress tests to measure fatigue in Ta\u015fan\u2019s new steel\u00a0showed improvement over other steels.\nUnderlying these findings are new nanoscale experimental techniques that Ta\u015fan employs to identify the multiple causes of failure in metal alloys. Ta\u015fan combines energy-dispersive X-ray spectroscopy and scanning electron and transmission electron microscopes to capture data on tension, bending, compression or nanoindentation of materials. These type of microscopic measurements are called in situ techniques.\nAnother technique studies how a metal alloy absorbs hydrogen and its effect on the metal. For example, Ta\u015fan played movies that show how plastic strain is accommodated to two phases in a high-entropy alloy.\n\u201cThese techniques allow us to see how the failure process is taking place, and we use these techniques to understand the mechanism of these failure modes and potentially repair mechanisms. Finally, we use this understanding to design new alloys that utilize these mechanisms,\u201d Ta\u015fan said. \u201cYou are trying to design a mechanism that can be used by the material over and over and over again to deal with the same type of crack that it is facing.\u201d\nTa\u015fan\u2019s investigations revealed three different types of crack closure mechanisms in steel: plasticity, phase transformation and crack-surface roughness. \u201cIf I want to activate all of these crack closure mechanisms, what I need to do is design a microstructure that is metastable, nano-laminate(d) and multi-phase at same time,\u201d he said. He said the new steel alloy successfully combines all three characteristics.\nMaterials Research Laboratory Director Carl V. Thompson noted that how a material is made determines its structure and its properties. These properties include mechanical, electrical, optical, magnetic and many other properties. Materials science and engineering encompasses an entire cycle from designing methods for making materials through analyzing their structure and properties, to evaluating how they perform. \u201cUltimately most people go through this process to make materials that perform in either a new way or in a better way for systems like automobiles, your cell phone, or medical equipment,\u201d Thompson said.\nEngineering perovskite solar cells\nSilvija Grade\u010dak, professor in the Department of Materials Science and Engineering, addressed the promise and the problems of perovskite solar cells. Hybrid organic-inorganic perovskites, such as methyl ammonium lead iodide, are a class of materials that are named after their crystal structure. \u201cThey are potentially lightweight, flexible and inexpensive as photovoltaic devices,\u201d Grade\u010dak said.\nHowever, perovskite solar devices tend to be unstable in water, oxygen exposure, UV irradiation, and under-voltage biasing. As many of these changes are dynamic and happen at nanoscale, understanding the structure of these materials can be complemented with information from electrical currents. \u201cBy using the electron beam, we can mimic the condition of the electron current within the device,\u201d she said.\u00a0\nGrade\u010dak uses a technique called cathodoluminescence to probe these perovskite materials. \u201cOur cathodoluminescence setup is unique because it enables so-called hyperspectral imaging. It means that the full optical signal is detected in each point of the complementary structural image. As the beam interacts with the sample, we are detecting light, and we do this as the electron beam moves across the sample. That is specifically important for samples that are unstable as they are irradiated with the electron beam,\u201d she says.\nThis technique revealed that perovskite material examined under an electron microscope while applying a voltage to the sample for one minute resulted in a dramatic current increase in the material. \u201cThat also corresponds to the I/V [current/voltage] measurements outside of the scanning electron microscope that we performed,\u201d she said. When the voltage bias is removed, the sample relaxes back to its initial state.\n\u201cWhat we think is really happening is that by biasing, there are ions that are moving and they agglomerate at the edges of the sample or at the grain boundaries, and after you remove the bias, they will relax back,\u201d Grade\u010dak said.\nWork in Grade\u010dak\u2019s group by Olivia Hentz PhD \u201918 combined photoluminescence data with Monte Carlo simulations to extract mobility of the defects that are moving. \u201cMore interesting, and how we can apply this method, is to understand how the material\u2019s properties are influenced by synthesis. If you synthesize the material and you change, for example, the grain size, we can think about whether these ions that are moving will have different mobilities inside of the grain versus along the grain boundaries,\u201d Grade\u010dak said.\nHentz found that the mobility at the grain boundaries is 1,500 times faster than in the bulk. \u201cThe ions do move in the material, they move under the biasing conditions and that mobility is very different inside of the grain and along the grain boundaries,\u201d Grade\u010dak said. \u201cBy engineering the material and engineering the grain size, one can influence by how much the material will be influenced during the device operation. And this result correlates with the fact that single crystalline perovskite materials are significantly more stable than polycrystalline ones.\u201d\nTransformative new tools\nIn the keynote address, BP Amoco Chemical Company Senior Research Chemist Matthew Kulzick detailed new X-ray technologies and sample chambers that are yielding insights into fighting metal corrosion, improving catalytic reactions and more. \u201cThe current evolution of tools is spectacular,\u201d he said, noting the stunning images at 20-nanometer scale showing highly localized composition of materials.\nMIT Nuclear Reactor Lab Director David E. Moncton discussed advances in X-ray tubes, noting that current versions of small scale X-ray tubes are about 100 times better than those of 100 years ago. X-ray source brilliance is increasing at two times Moore\u2019s Law, which predicted the exponential growth of transistors in silicon chips, he noted.\nStill Synchroton sources such as the Advanced Photon Source, a national user facility at Argonne National Laboratory, offer beam brilliance that is 12 orders of magnitude higher than X-ray tubes. \u201cAdvanced X-ray capability is the most important missing probe of matter at nano centers and materials research labs that are not located at synchrotron facilities,\u201d he said.\nCompact X-ray free-electron laser devices hold the promise of bringing synchrotron-like examination capabilities to campus research labs, Moncton said. Moncton, who was the founding director of the Advanced Photon Source, is collaborating with Associate Professor William S. Graves at Arizona State University, which is home to world\u2019s first compact X-ray free-electron laser (CXFEL).\n\u201cThe emittance is very similar to a synchrotron source,\u201d Moncton said. \u201cIf you built a compact X-ray FEL on this compact source platform, it would outperform today\u2019s synchrotron facilities by a number of orders of magnitude.\u201d\nX-ray phase contrast imaging has also advanced microscopy, Moncton said, displaying an image showing air bubbles in the lungs of a fruit fly. Pump-probe techniques enable studies of biological proteins performing bio-chemical processes in real time.\n\u201cHaving a local synchrotron-like source would be revolutionary,\u201d Moncton said.\nLess damaging microscope\nMIT professor of electrical engineering Karl Berggren described his efforts to develop a new type of electron microscope based on the quantum character of electrons to improve microscopy. One of the goals is to reduce radiation damage to biological samples from imaging them.\nWith support from the Gordon and Betty Moore Foundation, Berggren is collaborating on this research with professor of physics Mark Kasevich at Stanford University, professor of physics Peter Hommelhoff at the Friedrich Alexander University, Erlangen-N\u00fcrnberg, in Germany, and professor of physics Pieter Kruit at the Technical University of Delft in the Netherlands. \u201cWhat we\u2019d like to do is basically try to take advantage of the counter-intuitive quantum properties of electrons,\u201d Berggren said.\nIn one approach, he employs a series of electron beam splitters and mirrors to improve the performance of scanning electron microscopes. \u201cWhat we\u2019re doing now is essentially making a test bed by which we can develop all the electron optics to try to put together a machine,\u201d Berggren said. Along the way, his group has developed a microscope that lets you image the top and bottom of a sample at the same time.\n\u201cWe know that electrons at high voltage will pass through many samples with interacting with just a small phase shift,\u201d he said. \u201cIn fact, we want to work in that limit for imaging bio molecules.\u201d The right combination of beam splitters could reduce electron-induced damage to the sample by 100 times, he said.\nNanowire self-assembly\nFrances M. Ross, formerly of the Research Division at the IBM T. J. Watson Research Center and a new arrival at the Department of Materials Science and Engineering this academic year, described her observations of nanowire growth in an electron microscope. This vapor-liquid-solid process was first described in 1964, but the atomic-level details of how the nanowires grow could not be observed until recent improvements in electron microscopy technique.\nShowing a movie of a silicon nanowire growing from a gold-silicon catalyst droplet, Ross said, \u201cTo grow these silicon nanowires, we just put gold on silicon and heat it up. The gold and silicon automatically form droplets, in the same way that water forms droplets on a sheet of glass.\u201d When additional silicon is then supplied, the droplets act as a catalyst and a silicon nanowire grows from each droplet. \u201cNanowire growth illustrates the fact that we can get a self-assembly process that is intrinsically very simple to form a structure that can be quite complex,\u201d Ross explained. \u201cYou can see features like the atomic level structure of the nanowire and catalyst, the effect of temperature and gas environment, and even the dynamics of the growth interface and how the catalyst really works.\u201d The silicon nanowire grows in little jumps despite a steady flow of source material, she noted, providing detailed information on the pathways by which the atoms assemble into the nanowire.\nAdding nickel to this process resulted in a nickel disilicide particle embedded in the silicon nanowire \u2014 a quantum dot. \u201cYou almost expect to see unexpected things because the movies capture every point along the way as the material evolves,\u201d Ross said. \u201cIn situ microscopy is really the only way to get these type of detailed relations between the structure, the properties, and even the catalytic activity of individual nanoscale objects.\u201d\n\u201cWe\u2019re in a very exciting time for electron microscopy, where advances in instrumentation are helping us understand materials growth at the atomic scale,\u201d Ross said.\nUncovering crystal structure\nJames LeBeau, visiting professor of materials science and engineering, explained that scanning transmission electron microscopy provides direct imaging of atomic structure using an extremely small (less than 1x10-10m) electron probe. LeBeau uses the scanning transmission electron microscope to develop and apply new ways to characterize atomic structure of materials to understand their properties. Further, he is applying machine learning to control the microscope, using an approach similar to that used to enable self-driving cars to recognize signs and lane lines.\nBeyond imaging, \u201cwe can also acquire a full chemical spectrum at every single point in our dataset. This allows us to not only directly determine which atoms are in the material, but their bonding configuration as well,\u201d LeBeau explained. He displayed an image showing lanthanum atoms sharing a sub-lattice with strontium and aluminum sharing a sub-lattice with tantalum. \u201cThese datasets become directly interpretable. You see the chemistry,\u201d he said.\n\u201cWe can even use this data to measure the atomic scale electric field,\u201d LeBeau added, showing an image in which the color represents the electrostatic field vector and the intensity of the color represents its magnitude. LeBeau also was able to use these techniques to uncover the particular crystal structure of ferroelectric hafnium dioxide. The atomic scale insights are critical as hafnium dioxide is compatible with silicon processing technology, which will pave the way for new memory applications. \u201cBy combining different types of data, we can explain the origin or ferroelectricity in these films and really rule out alternative explanations,\u201d he said.\nTwenty graduate students and postdocs gave two-minute previews during the Materials Day Symposium, which was immediately followed by a poster session. In all, 60 presented research posters in La Sala de Puerto. The winning presenters were graduate students Vera Schroeder, Rachel C. Kurchin, Gerald J. Wang and Philipp Simons, and postdoc Mikhail Y. Shalaginov.\n"}, {"source": "MIT", "title": "Machine-learning system could aid critical decisions in sepsis care", "link": "/2018/machine-learning-sepsis-care-1107", "date": "8", "content": "Researchers from MIT and Massachusetts General Hospital (MGH) have developed a predictive model that could guide clinicians in deciding when to give potentially life-saving drugs to patients being treated for sepsis in the emergency room.\nSepsis is one of the most frequent causes of admission, and one of the most common causes of death, in the intensive care unit. But the vast majority of these patients first come in through the ER. Treatment usually begins with antibiotics and intravenous fluids, a couple liters at a time. If patients don\u2019t respond well, they may go into septic shock, where their blood pressure drops dangerously low and organs fail. Then it\u2019s often off to the ICU, where clinicians may reduce or stop the fluids and begin vasopressor medications such as norepinephrine and dopamine, to raise and maintain the patient\u2019s blood pressure.\nThat\u2019s where things can get tricky. Administering fluids for too long may not be useful and could even cause organ damage, so early vasopressor intervention may be beneficial. In fact, early vasopressor administration has been linked to improved mortality in septic shock. On the other hand, administering vasopressors too early, or when not needed, carries its own negative health consequences, such as heart arrhythmias and cell damage. But there\u2019s no clear-cut answer on when to make this transition; clinicians typically must closely monitor the patient\u2019s blood pressure and other symptoms, and then make a judgment call.\nIn a paper being presented this week at the American Medical Informatics Association\u2019s Annual Symposium, the MIT and MGH researchers describe a model that \u201clearns\u201d from health data on emergency-care sepsis patients and predicts whether a patient will need vasopressors within the next few hours. For the study, the researchers compiled the first-ever dataset of its kind for ER sepsis patients. In testing, the model could predict a need for a vasopressor more than 80 percent of the time.\nEarly prediction could, among other things, prevent an unnecessary ICU stay for a patient that doesn\u2019t need vasopressors, or start early preparation for the ICU for a patient that does, the researchers say.\n\u201cIt\u2019s important to have good discriminating ability between who needs vasopressors and who doesn\u2019t [in the ER],\u201d says first author Varesh Prasad, a PhD student in the Harvard-MIT Program in Health Sciences and Technology. \u201cWe can predict within a couple of hours if a patient needs vasopressors. If, in that time, patients got three liters of IV fluid, that might be excessive. If we knew in advance those liters weren\u2019t going to help anyway, they could have started on vasopressors earlier.\u201d\nIn a clinical setting, the model could be implemented in a bedside monitor, for example, that tracks patients and sends alerts to clinicians in the often-hectic ER about when to start vasopressors and reduce fluids. \u201cThis model would be a vigilance or surveillance system working in the background,\u201d says co-author Thomas Heldt, the W. M. Keck Career Development Professor in the MIT Institute of Medical Engineering and Science. \u201cThere are many cases of sepsis that [clinicians] clearly understand, or don\u2019t need any support with. The patients might be so sick at initial presentation that the physicians know exactly what to do. But there\u2019s also a \u2018gray zone,\u2019 where these kinds of tools become very important.\u201d\nCo-authors on the paper are James C. Lynch, an MIT graduate student; and Trent D. Gillingham, Saurav Nepal, Michael R. Filbin, and Andrew T. Reisner, all of MGH. Heldt is also an assistant professor of electrical and biomedical engineering in MIT\u2019s Department of Electrical Engineering and Computer Science and a principal investigator in the Research Laboratory of Electronics.\nOther models have been built to predict which patients are at risk for sepsis, or when to administer vasopressors, in ICUs. But this is the first model trained on the task for the ER, Heldt says. \u201c[The ICU] is a later stage for most sepsis patients. The ER is the first point of patient contact, where you can make important decisions that can make a difference in outcome,\u201d Heldt says.\nThe primary challenge has been a lack of an ER database. The researchers worked with MGH clinicians over several years to compile medical records of nearly 186,000 patients who were treated in the MGH emergency room from 2014 to 2016. Some patients in the dataset had received vasopressors within the first 48 hours of their hospital visit, while others hadn\u2019t. Two researchers manually reviewed all records of patients with likely septic shock to include the exact time of vasopressor administration, and other annotations. (The average time from presentation of sepsis symptoms to vasopressor initiation was around six hours.)\nThe records were randomly split, with 70 percent used for training the model and 30 percent for testing it. In training, the model extracted up to 28 of 58 possible features from patients who needed or didn\u2019t need vasopressors. Features included blood pressure, elapsed time from initial ER admission, total fluid volume administered, respiratory rate, mental status, oxygen saturation, and changes in cardiac stroke volume \u2014 how much blood the heart pumps in each beat.\nIn testing, the model analyzes many or all of those features in a new patient at set time intervals and looks for patterns indicative of a patient that ultimately needed vasopressors or didn\u2019t. Based on that information, it makes a prediction, at each interval, about whether the patient will need a vasopressor. In predicting whether patients needed vasopressors in the next two or more hours, the model was correct 80 to 90 percent of the time, which could prevent an excessive half a liter or more of administered fluids, on average.\n\u201cThe model basically takes a set of current vital signs, and a little bit of what the trajectory looks like, and determines that this current observation suggests this patient might need vasopressors, or this set of variables suggests this patient would not need them,\u201d Prasad says.\nNext, the researchers aim to expand the work to produce more tools that predict, in real-time, if ER patients may initially be at risk for sepsis or septic shock. \u201cThe idea is to integrate all these tools into one pipeline that will help manage care from when they first come into the ER,\u201d Prasad says.\nThe idea is to help clinicians at emergency departments in major hospitals such as MGH, which sees about 110,000 patients annually, focus on the most at-risk populations for sepsis. \u201cThe problem with sepsis is the presentation of the patient often belies the seriousness of the underlying disease process,\u201d Heldt says. \u201cIf someone comes in with weakness and doesn\u2019t feel right, a little bit of fluids may often do the trick. But, in some cases, they have underlying sepsis and can deteriorate very quickly. We want to be able to tell which patients have become better and which are on a critical path if left untreated.\u201d\nThe work was supported, in part, by a National Defense Science and Engineering Graduate Fellowship, the MIT-MGH Strategic Partnership, and by CRICO Risk Management Foundation and Nihon Kohden Corporation.\n"}, {"source": "MIT", "title": "Why some Wikipedia disputes go unresolved", "link": "/2018/wikipedia-disputes-unresolved-study-1106", "date": "8", "content": "Wikipedia has enabled large-scale, open collaboration on the internet\u2019s largest general-reference resource. But, as with many collaborative writing projects, crafting the content can be a contentious subject.\nOften, multiple Wikipedia editors will disagree on certain changes to articles or policies. One of the main ways to officially resolve such disputes is the Requests for Comment (RfC) process. Quarreling editors will publicize their deliberation on a forum, where other Wikipedia editors will chime in and a neutral editor will make a final decision.\nIdeally, this should solve all issues. But a novel study by MIT researchers finds debilitating factors \u2014\u00a0such as excessive bickering and poorly worded arguments \u2014 have led to about one-third of RfCs going unresolved.\nFor the study, the researchers compiled and analyzed the first-ever comprehensive dataset of RfC conversations, captured over an eight-year period, and conducted interviews with editors who frequently close RfCs, to understand why they don\u2019t find a resolution. They also developed a machine-learning model that leverages that dataset to predict when RfCs may go stale. And, they recommend digital tools that could make deliberation and resolution more effective.\n\u201cIt was surprising to see a full third of the discussions were not closed,\u201d says Amy X. Zhang, a PhD candidate in MIT\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL) and co-author on the paper, which is being presented at this week\u2019s ACM Conference on Computer-Supported Cooperative Work and Social Computing. \u201cOn Wikipedia, everyone\u2019s a volunteer. People are putting in the work, and they have interest \u2026 and editors may be waiting on someone to close so they can get back to editing. We know, looking through the discussions, the job of reading through and resolving a big deliberation is hard, especially with back and forth and contentiousness. [We hope to] help that person do that work.\u201d\nThe paper\u2019s co-authors are: first author Jane Im, a graduate student at the University of Michigan\u2019s School of Information; Christopher J. Schilling of the Wikimedia Foundation; and David Karger, a professor of computer science and CSAIL researcher.\n(Not) finding closure\nWikipedia offers several channels to solve editorial disputes, which involve two editors hashing out their problems, putting ideas to a simple majority vote from the community, or bringing the debate to a panel of moderators. Some previous Wikipedia research has delved into those channels and back-and-forth \u201cedit wars\u201d between contributors. \u201cBut RfCs are interesting, because there\u2019s much less of a voting mentality,\u201d Zhang says. \u201cWith other processes, at the end of day you\u2019ll vote and see what happens. [RfC participants] do vote sometimes, but it\u2019s more about finding a consensus. What\u2019s important is what\u2019s actually happening in a discussion.\u201d\nTo file an RfC, an editor drafts a template proposal, based on a content dispute that wasn\u2019t resolved in an article\u2019s basic \u201ctalk\u201d page, and invites comment by the broader community. Proposals run the gamut, from minor disagreements about a celebrity\u2019s background information to changes to Wikipedia\u2019s policies. Any editor can initiate an RfC and any editor \u2014\u00a0usually, more experienced ones \u2014 who didn\u2019t participate in the discussion and is considered neutral, may close a discussion. After 30 days, a bot automatically removes the RfC template, with or without resolution. RfCs can close formally with a summary statement by the closer, informally due to overwhelming agreement by participants, or be left stale, meaning removed without resolution. \u00a0\nFor their study, the researchers compiled a database consisting of about 7,000\u00a0RfC conversations from the English-language Wikipedia from 2011 to 2017, which included closing statements, author account information, and general reply structure. They also conducted interviews with 10 of Wikipedia\u2019s most frequent closers to better understand their motivations and considerations when resolving a dispute.\nAnalyzing the dataset, the researchers found that about 57 percent of RfCs were formally closed. Of the remaining 43 percent, 78 percent (or around 2,300) were left stale without informal resolution \u2014 or, about 33 percent of all the RfCs studied. Combining dataset analysis with the interviews, the researchers then fleshed out the major causes of resolution failure. Major issues include poorly articulated initial arguments, where the initiator is unclear about the issue or writes a deliberately biased proposal; excessive bickering during discussions that lead to more complicated, longer, argumentative threads that are difficult to fully examine; and simple lack of interest from third-party editors because topics may be too esoteric, among other factors.\nHelpful tools\nThe team then developed a machine-learning model to predict whether a given\u00a0RfC\u00a0would close (formally or informally) or go stale, by analyzing more than 60 features of the text, Wikipedia page, and editor account information. The model achieved a 75 percent accuracy for predicting failure or success within one week after discussion started. Some more informative features for prediction, they found, include the length of the discussion, number of participants and replies, number of revisions to the article, popularity of and interest in the topic, experience of the discussion participants, and the level of vulgarity, negativity, and general aggression in the comments.\nThe model could one day be used by RfC initiators to monitor a discussion as it\u2019s unfolding. \u201cWe think it could be useful for editors to know how to target their interventions,\u201d Zhang says. \u201cThey could post [the RfC] to more [Wikipedia forums] or invite more people, if it looks like it\u2019s in danger of not being resolved.\u201d\nThe researchers suggest Wikipedia could develop tools to help closers organize lengthy discussions, flag persuasive arguments and opinion changes within a thread, and encourage collaborative closing of RfCs.\nIn the future, the model and proposed tools could potentially be used for other community platforms that involve large-scale discussions and deliberations. Zhang points to online city-and community-planning forums, where citizens weigh in on proposals. \u201cPeople are discussing [the proposals] and voting on them, so the tools can help communities better understand the discussions \u2026 and would [also] be useful for the implementers of the proposals.\u201d\nZhang, Im, and other researchers have now built an external website for editors of all levels of expertise to come together to learn from one another, and more easily monitor and close discussions. \u201cThe work of closer is pretty tough,\u201d Zhang says, \u201cso there\u2019s a shortage of people looking to close these discussions, especially difficult, longer, and more consequential ones. This could help reduce the barrier to entry [for editors to become closers] and help them collaborate to close RfCs.\u201d\n\u201cWhile it is surprising that a third of these discussions were never resolved, [what\u2019s more] important are the reasons why discussions fail to come to closure, and the most interesting conclusions here come from the qualitative analyses,\u201d says Robert Kraut, a professor emeritus of human-computer interactions at Carnegie Melon University. \u201cSome [of the study\u2019s] findings transcend Wikipedia and can apply to many discussion in other settings.\u201d More work, he adds, could be done to improve the accuracy of the machine-learning model in order to provide more actionable insights to Wikipedia.\nThe study sheds light on how some RfC processes \u201cdeviate from established norms, leading to inefficiencies and biases,\u201d says Dario Taraborelli, director of research at the Wikimedia Foundation. \u201cThe results indicate that the experience of participants and the length of a discussion are strongly predictive of the timely closure of an RfC. This brings new empirical evidence to the question of how to make governance-related discussions more accessible to newcomers and members of underrepresented groups.\u201d\n"}, {"source": "MIT", "title": "Fleets of drones could aid searches for lost hikers", "link": "/2018/fleets-drones-help-searches-lost-hikers-1102", "date": "8", "content": "Finding lost hikers in forests can be a difficult and lengthy process, as helicopters and drones can\u2019t get a glimpse through the thick tree canopy. Recently, it\u2019s been proposed that autonomous drones, which can bob and weave through trees, could aid these searches. But the GPS signals used to guide the aircraft can be unreliable or nonexistent in forest environments.\nIn a paper being presented at the International Symposium on Experimental Robotics conference next week, MIT researchers describe an autonomous system for a fleet of drones to collaboratively search under dense forest canopies. The drones use only onboard computation and wireless communication \u2014 no GPS required.\nEach autonomous quadrotor drone is equipped with laser-range finders for position estimation, localization, and path planning. As the drone flies around, it creates an individual 3-D map of the terrain. Algorithms help it recognize unexplored and already-searched spots, so it knows when it\u2019s fully mapped an area. An off-board ground station fuses individual maps from multiple drones into a global 3-D map that can be monitored by human rescuers.\nIn a real-world implementation, though not in the current system, the drones would come equipped with object detection to identify a missing hiker. When located, the drone would tag the hiker\u2019s location on the global map. Humans could then use this information to plan a rescue mission.\n\u201cEssentially, we\u2019re replacing humans with a fleet of drones to make the search part of the search-and-rescue process more efficient,\u201d says first author Yulun Tian, a graduate student in the Department of Aeronautics and Astronautics (AeroAstro).\nThe researchers tested multiple drones in simulations of randomly generated forests, and tested two drones in a forested area within NASA\u2019s Langley Research Center. In both experiments, each drone mapped a roughly 20-square-meter area in about two to five minutes and collaboratively fused their maps together in real-time. The drones also performed well across several metrics, including overall speed and time to complete the mission, detection of forest features, and accurate merging of maps.\nCo-authors on the paper are: Katherine Liu, a PhD student in MIT\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL) and AeroAstro; Kyel Ok, a PhD student in CSAIL and the Department of Electrical Engineering and Computer Science; Loc Tran and Danette Allen of the NASA Langley Research Center; Nicholas Roy, an AeroAstro professor and CSAIL researcher; and Jonathan P. How, the Richard Cockburn Maclaurin Professor of Aeronautics and Astronautics.\n\n\n\n\n MIT \n\n\nExploring and mapping\nOn each drone, the researchers mounted a LIDAR system, which creates a 2-D scan of the surrounding obstacles by shooting laser beams and measuring the reflected pulses. This can be used to detect trees; however, to drones, individual trees appear remarkably similar. If a drone can\u2019t recognize a given tree, it can\u2019t determine if it\u2019s already explored an area.\nThe researchers programmed their drones to instead identify multiple trees\u2019 orientations, which is far more distinctive. With this method, when the LIDAR signal returns a cluster of trees, an algorithm calculates the angles and distances between trees to identify that cluster. \u201cDrones can use that as a unique signature to tell if they\u2019ve visited this area before or if it\u2019s a new area,\u201d Tian says.\nThis feature-detection technique helps the ground station accurately merge maps. The drones generally explore an area in loops, producing scans as they go. The ground station continuously monitors the scans. When two drones loop around to the same cluster of trees, the ground station merges the maps by calculating the relative transformation between the drones, and then fusing the individual maps to maintain consistent orientations.\n\u201cCalculating that relative transformation tells you how you should align the two maps so it corresponds to exactly how the forest looks,\u201d Tian says.\nIn the ground station, robotic navigation software called \u201csimultaneous localization and mapping\u201d (SLAM) \u2014 which both maps an unknown area and keeps track of an agent inside the area \u2014 uses the LIDAR input to localize and capture the position of the drones. This helps it fuse the maps accurately.\nThe end result is a map with 3-D terrain features. Trees appear as blocks of colored shades of blue to green, depending on height. Unexplored areas are dark but turn gray as they\u2019re mapped by a drone. On-board path-planning software tells a drone to always explore these dark unexplored areas as it flies around. Producing a 3-D map is more reliable than simply attaching a camera to a drone and monitoring the video feed, Tian says. Transmitting video to a central station, for instance, requires a lot of bandwidth that may not be available in forested areas.\nMore efficient searching\nA key innovation is a novel search strategy that let the drones more efficiently explore an area. According to a more traditional approach, a drone would always search the closest possible unknown area. However, that could be in any number of directions from the drone\u2019s current position. The drone usually flies a short distance, and then stops to select a new direction.\n\u201cThat doesn\u2019t respect dynamics of drone [movement],\u201d Tian says. \u201cIt has to stop and turn, so that means it\u2019s very inefficient in terms of time and energy, and you can\u2019t really pick up speed.\u201d\n\u00a0Instead, the researchers\u2019 drones explore the closest possible area, while considering their current direction. They believe this can help the drones maintain a more consistent velocity. This strategy \u2014 where the drone tends to travel in a spiral pattern \u2014 covers a search area much faster. \u201cIn search and rescue missions, time is very important,\u201d Tian says.\nIn the paper, the researchers compared their new search strategy with a traditional method. Compared to that baseline, the researchers\u2019 strategy helped the drones cover significantly more area, several minutes faster and with higher average speeds.\nOne limitation for practical use is that the drones still must communicate with an off-board ground station for map merging. In their outdoor experiment, the researchers had to set up a wireless router that connected each drone and the ground station. In the future, they hope to design the drones to communicate wirelessly when approaching one another, fuse their maps, and then cut communication when they separate. The ground station, in that case, would only be used to monitor the updated global map.\n"}, {"source": "MIT", "title": "Machines that learn language more like kids do", "link": "/2018/machines-learn-language-human-interaction-1031", "date": "8", "content": "Children learn language by observing their environment, listening to the people around them, and connecting the dots between what they see and hear. Among other things, this helps children establish their language\u2019s word order, such as where subjects and verbs fall in a sentence.\nIn computing, learning language is the task of syntactic and semantic parsers. These systems are trained on sentences annotated by humans that describe the structure and meaning behind words. Parsers are becoming increasingly important for web searches, natural-language database querying, and voice-recognition systems such as Alexa and Siri. Soon, they may also be used for home robotics.\nBut gathering the annotation data can be time-consuming and difficult for less common languages. Additionally, humans don\u2019t always agree on the annotations, and the annotations themselves may not accurately reflect how people naturally speak.\nIn a paper being presented at this week\u2019s Empirical Methods in Natural Language Processing conference, MIT researchers describe a parser that learns through observation to more closely mimic a child\u2019s language-acquisition process,\u00a0which could greatly extend the parser\u2019s capabilities. To learn the structure of language, the parser observes captioned videos, with no other information, and associates the words with recorded objects and actions. Given a new sentence, the parser can then use what it\u2019s learned about the structure of the language to accurately predict a sentence\u2019s meaning, without the video.\nThis \u201cweakly supervised\u201d approach \u2014 meaning it requires limited training data \u2014 mimics how children can observe the world around them and learn language, without anyone providing direct context. The approach could expand the types of data and reduce the effort needed for training parsers, according to the researchers. A few directly annotated sentences, for instance, could be combined with many captioned videos, which are easier to come by, to improve performance.\nIn the future, the parser could be used to improve natural interaction between humans and personal robots. A robot equipped with the parser, for instance, could constantly observe its environment to reinforce its understanding of spoken commands, including when the spoken sentences aren\u2019t fully grammatical or clear. \u201cPeople talk to each other in partial sentences, run-on thoughts, and jumbled language. You want a robot in your home that will adapt to their particular way of speaking \u2026 and still figure out what they mean,\u201d says co-author Andrei Barbu, a researcher in the Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Center for Brains, Minds, and Machines (CBMM) within MIT\u2019s McGovern Institute.\nThe parser could also help researchers better understand how young children learn language. \u201cA child has access to redundant, complementary information from different modalities, including hearing parents and siblings talk about the world, as well as tactile information and visual information, [which help him or her] to understand the world,\u201d says co-author Boris Katz, a principal research scientist and head of the InfoLab Group at CSAIL. \u201cIt\u2019s an amazing puzzle, to process all this simultaneous sensory input. This work is part of bigger piece to understand how this kind of learning happens in the world.\u201d\nCo-authors on the paper are: first author Candace Ross, a graduate student in the Department of Electrical Engineering and Computer Science and CSAIL, and a researcher in CBMM; Yevgeni Berzak PhD \u201917, a postdoc in the Computational Psycholinguistics Group in the Department of Brain and Cognitive Sciences; and CSAIL graduate student Battushig Myanganbayar.\nVisual learner\nFor their work, the researchers combined a semantic parser with a computer-vision component trained in object, human, and activity recognition in video. Semantic parsers are generally trained on sentences annotated with code that ascribes meaning to each word and the relationships between the words. Some have been trained on still images or computer simulations.\nThe new parser is the first to be trained using video, Ross says. In part, videos are more useful in reducing ambiguity. If the parser is unsure about, say, an action or object in a sentence, it can reference the video to clear things up. \u201cThere are temporal components \u2014\u00a0objects interacting with each other and with people \u2014\u00a0and high-level properties you wouldn\u2019t see in a still image or just in language,\u201d Ross says.\nThe researchers compiled a dataset of about 400 videos depicting people carrying out a number of actions, including picking up an object or putting it down, and walking toward an object. Participants on the crowdsourcing platform Mechanical Turk then provided 1,200 captions for those videos. They set aside 840 video-caption examples for training and tuning, and used 360 for testing. One advantage of using vision-based parsing is \u201cyou don\u2019t need nearly as much data \u2014 although if you had [the data], you could scale up to huge datasets,\u201d Barbu says.\nIn training, the researchers gave the parser the objective of determining whether a sentence accurately describes a given video. They fed the parser a video and matching caption. The parser extracts possible meanings of the caption as logical mathematical expressions. The sentence, \u201cThe woman is picking up an apple,\u201d for instance, may be expressed as: \u03bbxy. woman x, pick_up x y, apple y.\nThose expressions and the video are inputted to the computer-vision algorithm, called \u201cSentence Tracker,\u201d developed by Barbu and other researchers. The algorithm looks at each video frame to track how objects and people transform over time, to determine if actions are playing out as described. In this way, it determines if the meaning is possibly true of the video.\nConnecting the dots\nThe expression with the most closely matching representations for objects, humans, and actions becomes the most likely meaning of the caption. The expression, initially, may refer to many different objects and actions in the video, but the set of possible meanings serves as a training signal that helps the parser continuously winnow down possibilities. \u201cBy assuming that all of the sentences must follow the same rules, that they all come from the same language, and seeing many captioned videos, you can narrow down the meanings further,\u201d Barbu says.\nIn short, the parser learns through passive observation: To determine if a caption is true of a video, the parser by necessity must identify the highest probability meaning of the caption. \u201cThe only way to figure out if the sentence is true of a video [is] to go through this intermediate step of, \u2018What does the sentence mean?\u2019 Otherwise, you have no idea how to connect the two,\u201d Barbu explains. \u201cWe don\u2019t give the system the meaning for the sentence. We say, \u2018There\u2019s a sentence and a video. The sentence has to be true of the video. Figure out some intermediate representation that makes it true of the video.\u2019\u201d\nThe training produces a syntactic and semantic grammar for the words it\u2019s learned. Given a new sentence, the parser no longer requires videos, but leverages its grammar and lexicon to determine sentence structure and meaning.\nUltimately, this process is learning \u201cas if you\u2019re a kid,\u201d Barbu says. \u201cYou see world around you and hear people speaking to learn meaning. One day, I can give you a sentence and ask what it means and, even without a visual, you know the meaning.\u201d\n\u201cThis research is exactly the right direction for natural language processing,\u201d says Stefanie Tellex,\u00a0a professor of computer science at Brown University who focuses on helping robots use natural language to communicate with humans. \u201cTo interpret\u00a0grounded language, we need semantic representations, but it is not\u00a0practicable to make it available at training time. Instead, this work captures representations of compositional\u00a0structure using context from captioned videos. This is the paper I have been waiting for!\u201d\nIn future work, the researchers are interested in modeling interactions, not just passive observations. \u201cChildren interact with the environment as they\u2019re learning. Our idea is to have a model that would also use perception to learn,\u201d Ross says.\nThis work was supported, in part, by the CBMM, the National Science Foundation, a Ford Foundation Graduate Research Fellowship, the Toyota Research Institute, and the MIT-IBM Brain-Inspired Multimedia Comprehension project.\n"}, {"source": "MIT", "title": "Model paves way for faster, more efficient translations of more languages", "link": "/2018/unsupervised-model-faster-computer-translations-languages-1030", "date": "8", "content": "MIT researchers have developed a novel \u201cunsupervised\u201d language translation model \u2014\u00a0meaning it runs without the need for human annotations and guidance \u2014 that could lead to faster, more efficient computer-based translations of far more languages.\nTranslation systems from Google, Facebook, and Amazon require training models to look for patterns in millions of documents \u2014\u00a0such as legal and political documents, or news articles \u2014\u00a0that have been translated into various languages by humans. Given new words in one language, they can then find the matching words and phrases in the other language.\nBut this translational data is time consuming and difficult to gather, and simply may not exist for many of the 7,000 languages spoken worldwide. Recently, researchers have been developing \u201cmonolingual\u201d models that make translations between texts in two languages, but without direct translational information between the two.\nIn a paper being presented this week at the Conference on Empirical Methods in Natural Language Processing, researchers from MIT\u2019s Computer Science and Artificial Intelligence Laboratory (CSAIL) describe a model that runs faster and more efficiently than these monolingual models.\nThe model leverages a metric in statistics, called Gromov-Wasserstein distance, that essentially measures distances between points in one computational space and matches them to similarly distanced points in another space. They apply that technique to \u201cword embeddings\u201d of two languages, which are words represented as vectors \u2014 basically, arrays of numbers \u2014\u00a0with words of similar meanings clustered closer together. In doing so, the model quickly aligns the words, or vectors, in both embeddings that are most closely correlated by relative distances, meaning they\u2019re likely to be direct translations.\nIn experiments, the researchers\u2019 model performed as accurately as state-of-the-art monolingual models \u2014\u00a0and sometimes more accurately \u2014\u00a0but much more quickly and using only a fraction of the computation power.\n\u201cThe model sees the words in the two languages as sets of vectors, and maps [those vectors] from one set to the other by essentially preserving relationships,\u201d says the paper\u2019s co-author Tommi Jaakkola, a CSAIL researcher and the Thomas Siebel Professor in the Department of Electrical Engineering and Computer Science and the Institute for Data, Systems, and Society. \u201cThe approach could help translate low-resource languages or dialects, so long as they come with enough monolingual content.\u201d\nThe model represents a step toward one of the major goals of machine translation, which is fully unsupervised word alignment, says first author David Alvarez-Melis, a CSAIL PhD student: \u201cIf you don\u2019t have any data that matches two languages \u2026 you can map two languages and, using these distance measurements, align them.\u201d\nRelationships matter most\nAligning word embeddings for unsupervised machine translation isn\u2019t a new concept. Recent work trains neural networks to match vectors directly in word embeddings, or matrices, from two languages together. But these methods require a lot of tweaking during training to get the alignments exactly right, which is inefficient and time consuming.\nMeasuring and matching vectors based on relational distances, on the other hand, is a far more efficient method that doesn\u2019t require much fine-tuning. No matter where word vectors fall in a given matrix, the relationship between the words, meaning their distances, will remain the same. For instance, the vector for \u201cfather\u201d may fall in completely different areas in two matrices. But vectors for \u201cfather\u201d and \u201cmother\u201d will most likely always be close together.\n\u201cThose distances are invariant,\u201d Alvarez-Melis says. \u201cBy looking at distance, and not the absolute positions of vectors, then you can skip the alignment and go directly to matching the correspondences between vectors.\u201d\nThat\u2019s where Gromov-Wasserstein comes in handy. The technique has been used in computer science for, say, helping align image pixels in graphic design. But the metric seemed \u201ctailor made\u201d for word alignment, Alvarez-Melis says: \u201cIf there are points, or words, that are close together in one space, Gromov-Wasserstein is automatically going to try to find the corresponding cluster of points in the other space.\u201d\nFor training and testing, the researchers used a dataset of publicly available word embeddings, called FASTTEXT, with 110 language pairs. In these embeddings, and others, words that appear more and more frequently in similar contexts have closely matching vectors. \u201cMother\u201d and \u201cfather\u201d will usually be close together but both farther away from, say, \u201chouse.\u201d\nProviding a \u201csoft translation\u201d\nThe model notes vectors that are closely related yet different from the others, and assigns a probability that similarly distanced vectors in the other embedding will correspond. It\u2019s kind of like a \u201csoft translation,\u201d Alvarez-Melis says, \u201cbecause instead of just returning a single word translation, it tells you \u2018this vector, or word, has a strong correspondence with this word, or words, in the other language.\u2019\u201d\nAn example would be in the months of the year, which appear closely together in many languages. The model will see a cluster of 12 vectors that are clustered in one embedding and a remarkably similar cluster in the other embedding. \u201cThe model doesn\u2019t know these are months,\u201d Alvarez-Melis says. \u201cIt just knows there is a cluster of 12 points that aligns with a cluster of 12 points in the other language, but they\u2019re different to the rest of the words, so they probably go together well. By finding these correspondences for each word, it then aligns the whole space simultaneously.\u201d\nThe researchers hope the work serves as a \u201cfeasibility check,\u201d Jaakkola says, to apply Gromov-Wasserstein method to machine-translation systems to run faster, more efficiently, and gain access to many more languages.\nAdditionally, a possible perk of the model is that it automatically produces a value that can be interpreted as quantifying, on a numerical scale, the similarity between languages. This may be useful for linguistics studies, the researchers say. The model calculates how distant all vectors are from one another in two embeddings, which depends on sentence structure and other factors. If vectors are all really close, they\u2019ll score closer to 0, and the farther apart they are, the higher the score. Similar Romance languages such as French and Italian, for instance, score close to 1, while classic Chinese scores between 6 and 9 with other major languages.\n\u201cThis gives you a nice, simple number for how similar languages are \u2026 and can be used to draw insights about the relationships between languages,\u201d Alvarez-Melis says.\n"}, {"source": "MIT", "title": "Inside these fibers, droplets are on the move", "link": "/2018/fibers-microfluidics-medical-testing-1029", "date": "8", "content": "Microfluidics devices are tiny systems with microscopic channels that can be used for chemical or biomedical testing and research. In a potentially game-changing advance, MIT researchers have now incorporated microfluidics systems into individual fibers, making it possible to process much larger volumes of fluid, in more complex ways. In a sense, the advance opens up a new \u201cmacro\u201d era of microfluidics.\nTraditional microfluidics devices, developed and used extensively over the last couple of decades, are manufactured onto microchip-like structures and provide ways of mixing, separating, and testing fluids in microscopic volumes. Medical tests that only require a tiny droplet of blood, for example, often rely on microfluidics. But the diminutive scale of these devices also poses limitations; for example, they generally aren\u2019t useful for procedures that need larger volumes of liquid to detect substances present in minute amounts.\nA team of MIT researchers found a way around that, by making microfluidic channels inside fibers. The fibers can be made as long as needed to accommodate larger throughput, and they offer great control and flexibility over the shapes and dimensions of the channels. The new concept is described in a paper appearing this week in the journal Proceedings of the National Academy of Sciences, written by MIT graduate student Rodger Yuan, professors Joel Voldman and Yoel Fink, and four others.\nA multidisciplinary approach\nThe project came about as a result of a \u201cspeedstorming\u201d event (an amalgam of brainstorming and speed dating, an idea initiated by Professor Jeffrey Grossman) that was instigated by Fink when he was director of MIT\u2019s Research Laboratory of Electronics. The events are intended to help researchers develop new collaborative projects, by having pairs of students and postdocs brainstorm for six minutes at a time and come up with hundreds of ideas in an hour, which are ranked and evaluated by a panel. In this particular speedstorming session, students in electrical engineering worked with others in materials science and microsystems technology to develop a novel approach to cell sorting using a new class of multimaterial fibers.\nYuan explains that, although microfluidic technology has been extensively developed and widely used for processing small amounts of liquid, it suffers from three inherent limitations related to the devices\u2019 overall size, their channel profiles, and the difficulty of incorporating additional materials such as electrodes.\nBecause they are typically made using chip-manufacturing methods, microfluidic devices are limited to the size of the silicon wafers used in such systems, which are no more than about 8 inches across. And the photolithography methods used to make such chips limit the shapes of the channels; they can only have square or rectangular cross sections. Finally, any additional materials, such as electrodes for sensing or manipulating the channels\u2019 contents, must be individually placed in position in a separate process, severely limiting their complexity.\n\u201cSilicon chip technology is really good at making rectangular profiles, but anything beyond that requires really specialized techniques,\u201d says Yuan, who carried out the work as part of his doctoral research. \u201cThey can make triangles, but only with certain specific angles.\u201d With the new fiber-based method he and his team developed, a variety of cross-sectional shapes for the channels can be implemented, including star, cross, or bowtie shapes that may be useful for particular applications, such as automatically sorting different types of cells in a biological sample.\nIn addition, for conventional microfluidics, elements such as sensing or heating wires, or piezoelectric devices to induce vibrations in the sampled fluids, must be added at a later processing stage. But they can be completely integrated into the channels in the new fiber-based system.\nA shrinking profile\nLike other complex fiber systems developed over the years in the laboratory of co-author Yoel Fink, professor of materials science and engineering and head of the Advanced Functional Fabrics of America (AFFOA) consortium, these fibers are made by starting with an oversized polymer cylinder called a preform. These preforms contain the exact shape and materials desired for the final fiber, but in much larger form \u2014 which makes them much easier to make in very precise configurations. Then, the preform is heated and loaded into a drop tower, where it is slowly pulled through a nozzle that constricts it to a narrow fiber that\u2019s one-fortieth the diameter of the preform, while preserving all the internal shapes and arrangements.\nIn the process, the material is also elongated by a factor of 1,600, so that a 100-millimeter-long (4-inch-long) preform, for example, becomes a fiber 160 meters long (about 525 feet), thus dramatically overcoming the length limitations inherent in present microfluidic devices. This can be crucial for some applications, such as detecting microscopic objects that exist in very small concentrations in the fluid \u2014 for example, a small number of cancerous cells among millions of normal cells.\n\u201cSometimes you need to process a lot of material because what you\u2019re looking for is rare,\u201d says Voldman, a professor of electrical engineering who specializes in biological microtechnology. That makes this new fiber-based microfluidics technology especially appropriate for such uses, he says, because \u201cthe fibers can be made arbitrarily long,\u201d allowing more time for the liquid to remain inside the channel and interact with it.\nWhile traditional microfluidics devices can make long channels by looping back and forth on a small chip, the resulting twists and turns change the profile of the channel and affect the way the liquid flows, whereas in the fiber version these can be made as long as needed, with no changes in shape or direction, allowing uninterrupted flow, Yuan says.\nThe system also allows electrical components such as conductive wires to be incorporated into the fiber. These can be used for example to manipulate cells, using a method called dielectrophoresis, in which cells are affected differently by an electric field produced between two conductive wires on the sides of the channel.\nWith these conductive wires in the microchannel, one can control the voltage so the forces are \u201cpushing and pulling on the cells, and you can do it at high flow rates,\u201d Voldman says.\nAs a demonstration, the team made a version of the long-channel fiber device designed to separate cells, sorting dead cells from living ones, and proved its efficiency in accomplishing this task. With further development, they expect to be able to perform more subtle discrimination between cell types, Yuan says.\n\u201cFor me this was a wonderful example of how proximity between research groups at an interdisciplinary lab like RLE leads to groundbreaking research, initiated and led by a graduate student. We the faculty were essentially dragged in by our students,\u201d Fink says.\nThe researchers emphasize that they do not see the new method as a substitute for present microfluidics, which work very well for many applications. \u201cIt\u2019s not meant to replace; it\u2019s meant to augment\u201d present methods, Voldman says, allowing some new functions for particular uses that have not previously been possible.\n\u201cExemplifying the power of interdisciplinary collaboration, a new understanding arises here from unexpected combinations of manufacturing, materials science, biological flow physics, and microsystems design,\u201d says Amy Herr, a professor of bioengineering at the University of California at Berkeley, who was not involved in this research. She adds that this work \u201cadds important degrees of freedom \u2014 regarding geometry of fiber cross-section and material properties \u2014 to emerging fiber-based microfluidic design strategies.\u201d\nThe team included graduate student Jaemyon Lee, Hao Wei Su PhD \u201916, and postdocs Etgar Levy and Tural Khudryev. The work was supported by the National Science Foundation, the National Institutes of Health, the Defense Advanced Research Projects Agency, the U.S. Army Research Laboratory and the U.S. Army Research Office through the Institute for Soldier Nanotechnologies at MIT, and the Center for Materials Science and Engineering.\n"}, {"source": "MIT", "title": "HUBweek Policy Hackathon delivers local solutions", "link": "/2018/mit-idss-hubweek-policy-hackathon-delivers-solutions-local-challenges-1022", "date": "8", "content": "Students from MIT\u2019s Institute for Data, Systems and Society (IDSS) led a 24-hour policy hackathon\u00a0in Boston that called upon participants to form teams and analyze data sets to solve urban problems as part of the city-wide HUBweek festival. The hackathon was designed to support the 2018 HUBweek theme \u201cWe the Future.\u201d\u00a0\nSix teams pitched ideas to a panel of judges. Their proposals focused on improving transportation safety, employment opportunities, and public health in the Boston area.\n\u201cThe issues that we tackled are rooted in the needs of local citizens and cities,\u201d said Nathaniel Fruchter, a student organizer who is studying in\u00a0the Technology and Policy Program (TPP), a master\u2019s program at IDSS.\nJosh Wolff SM '15, a hackathon judge and TPP alumnus who now works with civic data in the City of Cambridge Information Technology Department called the hackathon \u201cvery relevant\u201d to work being done by the city's staff.\n\u201cEach of these hackathon topics is also an important city government initiative,\u201d Wolff said.\nThe winning team, who called themselves the\u00a0\u201cFuture Work Hackers,\u201d offered a solution for expanding employment opportunities to Boston-area millennials who do not have college degrees. The program would support private-public partnerships to help individuals gain marketable skills, and would also offer tax credits and incentives to companies that hired them.\nThe second place team, who dubbed themselves \u201cWorking Solutions,\u201d offered ways to improve the collection, coding, and utilization of citizen-sourced 311 call\u00a0data in order to reduce traffic accidents.\n\u201cSourcing challenges with local governments helped produce ideas that are actually very useful,\u201d said Kimberly Lucas, another hackathon judge who is director of civic research for the City of Boston. \u201cThe pitches I heard offered new insights, new ways of using data, and even new questions that are all directly relevant to what we're working on in City Hall.\u201d\nIDSS students ran their first policy hackathon on campus this past spring, and used that experience to scale the event to be a part of HUBweek, which bills itself as Boston\u2019s \u201cfestival for the future.\u201d The event features\u00a0workshops, installations, lectures, and conversations, as well as\u00a0performances and demonstrations in art, health, science, and technology.\nDonovan Guttieres, an IDSS student organizer, said one of his primary objectives for the hackathon was to demonstrate the importance of cross-disciplinary collaboration to tackling civic challenges. \u201cComplex societal problems are most effectively addressed when bringing together diverse groups of stakeholders working at the nexus of science, policy, and society,\u201d he said.\nFrom their position as judges, Lucas and Wolff agreed.\n\u201cThe multiplicity of perspectives on the same challenge was helpful,\u201d said Lucas, \u201cand the policy focus of the hackathon helped give deeper meaning and context to the challenges for us in city government.\u201d\nBoth judges also remarked on the direct usefulness of the policy proposals to city officials.\n\u201cFor local governments, policy reports and data analyses are often more actionable than traditional hackathon outputs like software prototypes or apps,\u201d Wolff said.\nEmpowering citizens to put actionable policy recommendations directly into the hands of local government was a major goal for the event organizers, and they were very satisfied with the results. Said Guttieres: \u201cWe wanted all participants to feel that anyone, given the right tools and opportunities, can contribute to making our future more sustainable.\u201d"}, {"source": "MIT", "title": "Computational science grad students awarded U.S. Department of Energy fellowships", "link": "/2018/mit-four-computational-science-grad-students-awarded-department-energy-fellowships-1019", "date": "8", "content": "Four MIT graduate students have been\u00a0awarded 2018 United States Department of Energy (DoE) Computational Science Graduate Fellowships to address intractable challenges in science and engineering. Nationwide, MIT garnered the most fellowships out of this year\u2019s 26 recipients.\nThe fellows receive full tuition and additional financial support, access to a network of alumni, and valuable practicum experience working in a DoE national laboratory. By supporting students like Kaley Brauer, Sarah Greer, William Moses, and Paul Zhang, the DoE aims to help train the next generation of computational scientists and engineers, incite collaboration and progress, and advance the future of the field by bringing more visibility to computational science careers.\nKaley Brauer is a graduate student in the Department of Physics. Her computational work in the Kavli Institute for Astrophysics and Space Research is uncovering new details about how galaxies form \u2014 including the origin of the Milky Way. Using high-performance computing simulations and theoretical models, she is identifying processes that underlie galaxy formation to learn more about properties of the early universe.\n\u201cYou need a detailed model to turn back the clock and learn about how a galaxy evolved step by step,\u201d Brauer says. \u201cIn a supercomputer, you can see how things move and make adjustments so that you end up with a galaxy that looks like the galaxy we see today. It\u2019s really fun.\u201d\nBrauer says\u00a0that while she originally wanted to be a scientific illustrator, an undergraduate cosmology class left her eager to learn more. Her current research allows her to combine her interest in both design and cosmology, and she hopes to focus her practicum on scientific visualization.\n\u201cI'm very excited that Kaley was chosen as a fellow,\u201d says\u00a0Anna Frebel, an associate professor of physics\u00a0and Brauer\u2019s advisor. \u201cIt enables her to do the type of computational research she\u2019s most excited about: to study galaxy formation and understand the evolution of our Milky Way Galaxy.\u201d\nSarah Greer is a graduate student in the Computational Science and Engineering (CSE)/Department of Mathematics PhD program. Greer\u2019s undergraduate research in geoscience focused on seismic data processing and improving visualizations of the Earth\u2019s subsurface. She intends to build on this work through her graduate research by using computational mathematics to address large-scale geophysical problems.\nGreer says\u00a0she is grateful for the opportunities that the fellowship affords, including a plan of study that encourages her to take risks.\n\u201cIt has helped me go outside my comfort zone and find areas I\u2019m interested in that I wouldn\u2019t have explored otherwise,\u201d Greer says. \u201cI also really like that the practicum lab component gives us the chance to try something out and see if it\u2019s the right career option.\u201d\nGreer\u2019s advisor, Laurent Demanet, an associate professor of applied mathematics, noted that modern geophysics has benefited from interdisciplinary researchers like Greer, who bring fresh perspectives to longstanding challenges.\n\u201cSarah\u2019s impressive background is a rare blend of data/signal processing, computational mathematics, and Earth sciences,\u201d Demanet says. \u201cIt was not a difficult decision to admit her in the new CSE-math PhD program at MIT, and we were all glad that the DoE felt the same way about awarding her this fellowship.\u201d\nWilliam \u201cBilly\u201d\u00a0Moses is a graduate student in the Department of Electrical Engineering and Computer Science. Moses also completed undergraduate and master's degrees at MIT in computer science and physics. His current research in the Computer Science and Artificial Intelligence Laboratory (CSAIL) focuses on performance engineering \u2014 strategies to improve ease of use, speed, and efficiency in computing. In addition to developing programs that write code, he works on programs called compilers that allow code to run on different machines.\n\u201cI really enjoy working on these problems,\u201d Moses said. \u201cSucceeding at them lets everyone take advantage of the latest advances in computer science without folks needing to spend five years in computer science graduate school.\u201d\nMoses described how the financial assistance and connections through the fellowship would support his research and career.\n\u201cI have the freedom to work on what I think is important, without necessarily searching for funding,\u201d Moses says. \u201cWhat really sets the DoE fellowship apart is the community it makes between the fellows and the national labs. Being a fellow in the program means that I have this wealth of resources out there for me.\u201d\n\u201cBilly is the kind of student who makes MIT a great place for research,\u201d says Moses\u2019 advisor, Charles Leiserson, a professor of computer science and engineering. Leiserson says\u00a0that Moses, as an undergraduate, received a best paper award at the 2017 Symposium on Principles and Practice of Parallel Programming for modifying a highly complicated, 4-million-line compiler \u2014 \u201ca feat that seasoned compiler engineers deemed well-nigh impossible,\u201d Leiserson says. \u201cI'm delighted that he has chosen graduate school at MIT to continue his research.\u201d\nPaul Zhang is a graduate student in the Department of Electrical Engineering and Computer Science. Zhang conducts research in the geometric data processing group in CSAIL with his advisor, Justin Solomon, an assistant professor of electrical engineering and computer science.\nThe geometric data processing group works on geometric problems in computer graphics, machine learning, and computer vision. Zhang is currently studying hexahedral meshing, a longstanding challenge that involves decomposing objects into cube-like elements for use in fluid simulation.\nZhang noted that the DoE fellowship provides important benefits beyond financial support. \u201cIn addition to the funding, it gives me the opportunity to meet other experts in my field,\u201d Zhang says. \u201cIt also gives me opportunities to use national lab resources like supercomputers.\u201d\nSolomon says that in his time as a PhD student, Zhang \u201chas already blown me away with his creativity and productivity \u2014 and he has achieved meaningful progress on some open research problems.\u201d\n\u201cHe is an obvious choice for this fellowship who will succeed in graduate school and become a top leader in the computational science community,\u201d Solomon says.\nZhang and the 2018 cohort join the 10 other MIT students currently supported by the DoE Computational Science Graduate Fellowship Program. Administered by the Krell Institute and funded by the DoE\u2019s Office of Science and the National Nuclear Security Administration, the fellowship program has supported more than 425 talented computational science students across the country since 1991.\n"}, {"source": "MIT", "title": "School of Engineering third quarter 2018 awards", "link": "/2018/school-engineering-third-quarter-awards-1019", "date": "8", "content": "Members of the MIT engineering faculty receive many\u00a0awards in recognition of their scholarship, service, and overall excellence. Every quarter, the School of Engineering publicly recognizes\u00a0their achievements by highlighting the\u00a0honors, prizes, and medals won by faculty working in our academic departments, labs, and centers.\nAnant Agarwal, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, won the 2018 Yidan Prize for Educational Development Laureate on Sept. 15.\u00a0\nAngela Belcher, of the departments of Materials Science and Engineering\u00a0and Biological Engineering, won the Xconomy Award for Innovation at the Intersection on July 18.\nMartin Bazant, of the departments of Chemical Engineering and Mathematics, became a fellow of the American Physical Society on Sept. 26.\nSvetlana Boriskina, of the Department of Mechanical Engineering, was elected to the Optical Society Board of Directors on Sept. 18.\nRichard Braatz, of the Department of Chemical Engineering, was named a fellow of American Institute of Chemical Engineers on Aug. 3.\nMarty Culpepper, of the Department of Mechanical Engineering, was named the Class of 1960 Fellow on Sept. 21.\nLuca Daniel, of the Department of Electrical Engineering and Computer Science\u00a0and the\u00a0Research Lab of Electronics, won the Best Paper Award for the IEEE Transactions on Components, Packaging, and Manufacturing Technologies on Aug. 13.\nConstantinos Daskalakis, of the Department of Electrical Engineering and Computer Science and the Computer Science and Artificial Intelligence Laboratory, won the Simons Investigator Award in Theoretical Computer Science from the Simons Foundation on July 1; he also won the Rolf Nevanlinna Prize from the International Mathematics Union on Aug. 1.\nDomitilla Del Vecchio, of the Department of Mechanical Engineering, won the National Science Foundation Understanding the Rules of Life Award on Sept. 21.\nSrini Devadas, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, won the Charles A. Desoer Technical Achievement Award of IEEE Circuits and Systems on July 1.\nPiotr Indyk, of the Department of Electrical Engineering and Computer Science and the Computer Science and Artificial Intelligence Laboratory, was appointed as the Thomas D. and Virginia W. Cabot Professor on Sept. 13.\nLynn W. Gelhar, of the Department of Civil and Environmental Engineering, won the Charles V. Theis Award on Aug. 1.\nPolina Golland, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, was named the Henry Ellis Warren (1894) Chair on Sept. 13.\nMartha Gray, of the Department of Electrical Engineering and Computer Science\u00a0and the Institute for Medical Engineering and Science, won the Civil Servants Social Security and Services Institute Memorial Award on June 12.\nCharles Harvey, of the Department of Civil and Environmental Engineering, was awarded an AGU Fellowship on Aug. 9.\nAsegun Henry, of the Department of Mechanical Engineering, won the 2018 Bergles-Rohsenow Young Investigator Award in Heat Transfer on Aug. 28.\nJeffrey A. Hoffman, of the Department of Aeronautics and Astronautics,\u00a0won the Best Technical Paper Award at the 31st Annual Congress of the Association of Space Explorers on Sept. 14.\nQing Hu, of the Department of Electrical Engineering and Computer Science\u00a0and the Research Lab of Electronics, won the Kenneth J Button Prize at the International Conference on Infrared, Millimeter, and Terahertz Waves on Sept. 14.\nKlavs Jensen, of the Department of Chemical Engineering and Materials Science and Engineering, was named the 2018 American Institute of Chemical Engineers Prausnitz Institute Lecturer on Aug. 21.\nRobert S. Langer, of the Department of Chemical Engineering, was awarded honorary foctorates from the University of Limerick in Ireland and from Universit\u00e9 Laval in Canada; he also won the Leadership Award for Historic Scientific Advancement from the American Chemical Society, the 2018 Leadership Award for Historic Scientific Advancement from the American Chemical Society, and the 2018 Alpha Omega Dental Fraternity Achievement Medal Award; in addition, he was inducted into Advanced Materials Hall of Fame on Aug. 1.\nCharles Leiserson, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, won the Association for Computing Machinery SIGCOMM Networking Systems Award on Aug. 28.\nAleksander Madry, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, won the Presburger Award for Young Scientists from the European Association for Theoretical Computer Science on July 13.\nTom Magnanti, of the Laboratory for Information and Decision Systems, was honored with Singapore\u2019s National Day Award on Aug. 17.\nHeidi Nepf, of the Department of Civil and Environmental Engineering, was awarded an AGU Fellowship on Aug. 9.\nDava Newman, of the Department of Aeronautics and Astronautics, won the 2018 Lowell Thomas Award on July 11.\nAsu Ozdaglar, of the Department of Electrical Engineering and Computer Science, was named the School of Engineering Distinguished Professor of Engineering on Sept. 13.\nPablo Parrilo, of the Department of Electrical Engineering and Computer Science, was named the Joseph F. and Nancy P. Keithley Professor on Sept. 13.\nAlberto Rodriguez, of the Department of Mechanical Engineering, won the Amazon Robotics Best Systems Paper Award in Manipulation on Sept. 14.\nHadley Sikes, of the Department of Chemical Engineering, was awarded the 2018 Best of BIOT (ACS Division of Biochemical Technology) Award on Sept. 25.\nMichael Strano, of the Department of Chemical Engineering and the MIT Energy Initiative, will lead the new Energy Frontier Research Center to be established at MIT on June 29.\nRussell Tedrake, of the Department of Electrical Engineering and Computer Science\u00a0and the Computer Science and Artificial Intelligence Laboratory, won the International Journal of Robotics Inaugural Paper of the Year Award on July 6.\nJohn Tsitsiklis, of the Department of Electrical Engineering and Computer Science, was awarded an honorary doctorate from the Athens University of Economics and Business; he also won the IEEE Control Systems Award on June 30.\nDennis Whyte, of the Department of Nuclear Science and Engineering and the Plasma Science and Fusion Center, won the Fusion Power Associates Leadership Award on Sept. 25.\nGregory Wornell, of the Department of Electrical Engineering and Computer Science and the Research Lab of Electronics, won the IEEE Leon K. Kirchmayer Graduate Teaching Award on Sept. 19.\nXuanhe Zhao, of the Department of Mechanical Engineering, won the Materials Today Rising Star Award on Sept. 19.\n"}]}